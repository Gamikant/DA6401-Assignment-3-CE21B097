{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100598cd-0ff8-4a82-8c52-3b73658f18b5",
   "metadata": {},
   "source": [
    "# Install Libraries and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefee210-5bea-417a-af3c-02b9a371c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Concatenate, AdditiveAttention, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split # Though not directly used in sweep, good to have\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker # For heatmap ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba4e99-f669-4378-89b2-977486b702d0",
   "metadata": {},
   "source": [
    "# Wandb Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bce6ff2-1bd0-4640-a67a-d94d2d6967ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ce21b097 (ce21b097-indian-institute-of-technology-madras) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec0420-10c7-4597-b2b8-5c65221b7ae3",
   "metadata": {},
   "source": [
    "# Data Loading and Initial Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79785683-5912-4dfd-83b0-2736dd1b799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 44202\n",
      "Validation samples: 4358\n",
      "Test samples: 4502\n",
      "\n",
      "Sample training data:\n",
      "Input: an, Target: अं\n",
      "Input: ankganit, Target: अंकगणित\n",
      "Input: uncle, Target: अंकल\n"
     ]
    }
   ],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"Loads data from a TSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t', header=None, on_bad_lines='skip', names=['native', 'roman', 'count'])\n",
    "        df.dropna(subset=['native', 'roman'], inplace=True)\n",
    "        input_texts = df['roman'].astype(str).tolist()\n",
    "        target_texts = df['native'].astype(str).tolist()\n",
    "        return input_texts, target_texts\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {filepath}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# --- Define file paths ---\n",
    "dataset_base_dir = 'dakshina_dataset_v1.0' \n",
    "language = 'hi' # Hindi\n",
    "\n",
    "train_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.train.tsv')\n",
    "dev_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.dev.tsv')\n",
    "test_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.test.tsv')\n",
    "\n",
    "# Load data\n",
    "input_texts_train_full, target_texts_train_full = load_data(train_file)\n",
    "input_texts_val, target_texts_val = load_data(dev_file)\n",
    "input_texts_test, target_texts_test = load_data(test_file)\n",
    "\n",
    "# For sweeps, we can use the same split as before or the full training data\n",
    "input_texts_train, target_texts_train = input_texts_train_full, target_texts_train_full\n",
    "\n",
    "print(f\"Training samples: {len(input_texts_train)}\")\n",
    "print(f\"Validation samples: {len(input_texts_val)}\")\n",
    "print(f\"Test samples: {len(input_texts_test)}\")\n",
    "\n",
    "if len(input_texts_train) > 0 and len(target_texts_train) > 0:\n",
    "    print(\"\\nSample training data:\")\n",
    "    for i in range(min(3, len(input_texts_train))):\n",
    "        print(f\"Input: {input_texts_train[i]}, Target: {target_texts_train[i]}\")\n",
    "else:\n",
    "    print(\"No training data loaded. Please check file paths and content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c660e-c9a1-4481-94a4-a8dc886ac52f",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Vocabulary, Tokenization, Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e457aa-18cb-4d81-b272-decd90740d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique input tokens: 26\n",
      "Number of unique output tokens: 65\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n",
      "\n",
      "Shape of encoder_input_train: (44202, 20)\n",
      "Shape of decoder_input_train: (44202, 21)\n",
      "Shape of decoder_target_train: (44202, 21, 65)\n",
      "Shape of encoder_input_val: (4358, 20)\n"
     ]
    }
   ],
   "source": [
    "# --- Character sets and tokenization ---\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "all_input_texts_for_vocab = input_texts_train_full + input_texts_val + input_texts_test\n",
    "all_target_texts_for_vocab = target_texts_train_full + target_texts_val + target_texts_test\n",
    "\n",
    "\n",
    "for text in all_input_texts_for_vocab:\n",
    "    for char in str(text): # Ensuring text is string\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "for text in all_target_texts_for_vocab:\n",
    "    for char in str(text): # Ensuring text is string\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "# Adding special tokens\n",
    "SOS_TOKEN = '\\t' # Start Of Sequence\n",
    "EOS_TOKEN = '\\n' # End Of Sequence\n",
    "target_characters.add(SOS_TOKEN)\n",
    "target_characters.add(EOS_TOKEN)\n",
    "\n",
    "\n",
    "input_char_list = sorted(list(input_characters))\n",
    "target_char_list = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_char_list)\n",
    "num_decoder_tokens = len(target_char_list)\n",
    "\n",
    "input_token_index = {char: i for i, char in enumerate(input_char_list)}\n",
    "target_token_index = {char: i for i, char in enumerate(target_char_list)}\n",
    "\n",
    "reverse_input_char_index = {i: char for char, i in input_token_index.items()}\n",
    "reverse_target_char_index = {i: char for char, i in target_token_index.items()}\n",
    "\n",
    "# Determining max sequence lengths from all data splits\n",
    "all_input_texts_combined = input_texts_train_full + input_texts_val + input_texts_test\n",
    "all_target_texts_combined = target_texts_train_full + target_texts_val + target_texts_test\n",
    "\n",
    "max_encoder_seq_length = max(len(str(text)) for text in all_input_texts_combined)\n",
    "max_decoder_seq_length = max(len(str(text)) for text in all_target_texts_combined) + 2 # +2 for SOS and EOS\n",
    "\n",
    "print(f\"\\nNumber of unique input tokens: {num_encoder_tokens}\")\n",
    "print(f\"Number of unique output tokens: {num_decoder_tokens}\")\n",
    "print(f\"Max sequence length for inputs: {max_encoder_seq_length}\")\n",
    "print(f\"Max sequence length for outputs: {max_decoder_seq_length}\")\n",
    "\n",
    "# --- Vectorizing the data ---\n",
    "def vectorize_data(input_texts, target_texts):\n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(str(input_text)): # Ensuring input_text is string\n",
    "            if t < max_encoder_seq_length and char in input_token_index:\n",
    "                 encoder_input_data[i, t] = input_token_index[char]\n",
    "        \n",
    "        processed_target_text = SOS_TOKEN + str(target_text) + EOS_TOKEN # Ensuring target_text is string\n",
    "        for t, char in enumerate(processed_target_text):\n",
    "            if t < max_decoder_seq_length:\n",
    "                if char in target_token_index:\n",
    "                    decoder_input_data[i, t] = target_token_index[char]\n",
    "                    if t > 0: \n",
    "                        decoder_target_data[i, t - 1, target_token_index[char]] = 1.0 \n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "# Vectorizing the training and validation sets (using the 'train' subset for initial sweep training if preferred)\n",
    "encoder_input_train, decoder_input_train, decoder_target_train = vectorize_data(input_texts_train, target_texts_train)\n",
    "encoder_input_val, decoder_input_val, decoder_target_val = vectorize_data(input_texts_val, target_texts_val)\n",
    "# Test data will be vectorized later before final evaluation.\n",
    "\n",
    "print(\"\\nShape of encoder_input_train:\", encoder_input_train.shape)\n",
    "print(\"Shape of decoder_input_train:\", decoder_input_train.shape)\n",
    "print(\"Shape of decoder_target_train:\", decoder_target_train.shape)\n",
    "print(\"Shape of encoder_input_val:\", encoder_input_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c2ba1-bad8-4a8a-92af-e8739214f268",
   "metadata": {},
   "source": [
    "# Bahdanau Attention Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6ac9c3-d4af-44b5-b215-3aa1e0623755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units) # For encoder outputs\n",
    "        self.W2 = tf.keras.layers.Dense(units) # For decoder hidden state\n",
    "        self.V = tf.keras.layers.Dense(1)      # To compute the score\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden_size) (decoder hidden state)\n",
    "        # values shape == (batch_size, max_len, hidden_size) (encoder outputs)\n",
    "\n",
    "        # Expand query to broadcast addition along sequence length dimension\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(query_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884545dc-8eb2-4102-8acf-f9f325cefcdb",
   "metadata": {},
   "source": [
    "# Attention Model Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322d97e5-1400-486a-9c64-d87704317b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_seq2seq_model(config):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(None,), name=\"encoder_inputs\")\n",
    "    enc_emb = Embedding(num_encoder_tokens, config.input_embedding_size, name=\"encoder_embedding\")(encoder_inputs)\n",
    "\n",
    "    # Selecting RNN cell type\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        RNNCellEncoder = LSTM\n",
    "        RNNCellDecoder = LSTM\n",
    "    elif config.cell_type == \"GRU\":\n",
    "        RNNCellEncoder = GRU\n",
    "        RNNCellDecoder = GRU\n",
    "    else:\n",
    "        RNNCellEncoder = keras.layers.SimpleRNN\n",
    "        RNNCellDecoder = keras.layers.SimpleRNN\n",
    "\n",
    "    # For simplicity and effective attention, encoder returns all sequences.\n",
    "    # Using a single layer for encoder as suggested for simplicity, but configurable.\n",
    "    encoder_outputs_list = []\n",
    "    current_encoder_output = enc_emb\n",
    "    encoder_states = [] # For the final state\n",
    "\n",
    "    for i in range(config.encoder_layers):\n",
    "        is_last_layer = (i == config.encoder_layers - 1)\n",
    "        encoder_rnn = RNNCellEncoder(config.hidden_size,\n",
    "                                     return_sequences=True, # Crucial for attention\n",
    "                                     return_state=True,\n",
    "                                     dropout=config.dropout_rate,\n",
    "                                     name=f\"encoder_{config.cell_type}_{i}\")\n",
    "        if config.cell_type == \"LSTM\":\n",
    "            current_encoder_output, state_h, state_c = encoder_rnn(current_encoder_output)\n",
    "            if is_last_layer:\n",
    "                encoder_states = [state_h, state_c]\n",
    "        else: # GRU or SimpleRNN\n",
    "            current_encoder_output, state_h = encoder_rnn(current_encoder_output)\n",
    "            if is_last_layer:\n",
    "                encoder_states = [state_h]\n",
    "    \n",
    "    encoder_all_outputs = current_encoder_output \n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
    "    dec_emb_layer = Embedding(num_decoder_tokens, config.input_embedding_size, name=\"decoder_embedding\")\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "    # Decoder RNN - single layer as suggested for simplicity, but configurable\n",
    "    # It will process one timestep at a time in the training model for clarity,\n",
    "    # though Keras handles the loop.\n",
    "    decoder_rnn_layer = RNNCellDecoder(config.hidden_size,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   dropout=config.dropout_rate,\n",
    "                                   name=f\"decoder_{config.cell_type}\")\n",
    "\n",
    "    # Attention Layer\n",
    "    attention_layer = BahdanauAttention(config.hidden_size) # Attention units often same as hidden_size\n",
    "\n",
    "    all_decoder_outputs = []\n",
    "\n",
    "    # Initial decoder hidden state:\n",
    "    decoder_hidden_states = encoder_states # From last encoder layer\n",
    "    \n",
    "    # Let's use the decoder_rnn_layer to process the entire sequence of decoder embeddings\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        decoder_rnn_outputs, _, _ = decoder_rnn_layer(dec_emb, initial_state=decoder_hidden_states)\n",
    "    else: # GRU / SimpleRNN\n",
    "        decoder_rnn_outputs, _ = decoder_rnn_layer(dec_emb, initial_state=decoder_hidden_states)\n",
    "    \n",
    "    context_vector_seq, attention_weights_seq = tf.keras.layers.AdditiveAttention(name=\"attention_layer\")(\n",
    "        [decoder_rnn_outputs, encoder_all_outputs], return_attention_scores=True\n",
    "    )\n",
    "    # context_vector_seq shape: (batch_size, target_seq_len, encoder_hidden_size)\n",
    "    # attention_weights_seq shape: (batch_size, target_seq_len, input_seq_len)\n",
    "\n",
    "    # Concatenating context vector with decoder RNN output\n",
    "    decoder_concat_input = Concatenate(axis=-1, name=\"concat_layer\")([decoder_rnn_outputs, context_vector_seq])\n",
    "\n",
    "    # Final output layer\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\", name=\"decoder_output_dense\")\n",
    "    decoder_outputs_final = decoder_dense(decoder_concat_input)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs_final)\n",
    "    \n",
    "    # Compile\n",
    "    optimizer_choice = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "    # Allow other optimizers from config if specified\n",
    "    if hasattr(config, 'optimizer'):\n",
    "        if config.optimizer == 'nadam':\n",
    "            optimizer_choice = tf.keras.optimizers.Nadam(learning_rate=config.learning_rate)\n",
    "        elif config.optimizer == 'rmsprop':\n",
    "            optimizer_choice = tf.keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer_choice, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996eacc-ed5d-479b-81a8-a3e9b51e9456",
   "metadata": {},
   "source": [
    "# Inference Models for Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d8f421-2c1e-4f94-a89a-bd753ce2db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_inference_models(training_model, config):\n",
    "    # --- Encoder Model ---\n",
    "    encoder_inputs_inf = training_model.get_layer(\"encoder_inputs\").input\n",
    "    encoder_embedding_inf = training_model.get_layer(\"encoder_embedding\")(encoder_inputs_inf)\n",
    "    \n",
    "    current_encoder_output_inf = encoder_embedding_inf\n",
    "    encoder_states_inf = [] # Final states of the last encoder layer\n",
    "    \n",
    "    for i in range(config.encoder_layers):\n",
    "        encoder_rnn_layer_inf = training_model.get_layer(f\"encoder_{config.cell_type}_{i}\")\n",
    "        if config.cell_type == \"LSTM\":\n",
    "            current_encoder_output_inf, state_h_enc, state_c_enc = encoder_rnn_layer_inf(current_encoder_output_inf)\n",
    "            if i == config.encoder_layers - 1: # Last layer\n",
    "                encoder_states_inf = [state_h_enc, state_c_enc]\n",
    "        else: # GRU or SimpleRNN\n",
    "            current_encoder_output_inf, state_h_enc = encoder_rnn_layer_inf(current_encoder_output_inf)\n",
    "            if i == config.encoder_layers - 1: # Last layer\n",
    "                encoder_states_inf = [state_h_enc]\n",
    "    \n",
    "    encoder_all_outputs_inf = current_encoder_output_inf # All hidden states from last encoder layer\n",
    "    encoder_model_inf = Model(encoder_inputs_inf, [encoder_all_outputs_inf] + encoder_states_inf)\n",
    "\n",
    "    # --- Decoder Model for Inference ---\n",
    "    decoder_hidden_size = config.hidden_size # Assuming decoder hidden size is same as attention units\n",
    "    \n",
    "    # Inputs for the decoder step\n",
    "    decoder_input_single_step = Input(shape=(1,), name=\"decoder_input_single_step\") # One token\n",
    "    encoder_all_outputs_as_input = Input(shape=(max_encoder_seq_length, config.hidden_size), name=\"encoder_all_outputs_as_input\") # From encoder\n",
    "\n",
    "    # Decoder initial states (list of tensors, one for h, one for c if LSTM)\n",
    "    decoder_initial_states_inputs = []\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        decoder_state_input_h = Input(shape=(decoder_hidden_size,), name=\"decoder_state_h_input\")\n",
    "        decoder_state_input_c = Input(shape=(decoder_hidden_size,), name=\"decoder_state_c_input\")\n",
    "        decoder_initial_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    else: # GRU or SimpleRNN\n",
    "        decoder_state_input_h = Input(shape=(decoder_hidden_size,), name=\"decoder_state_h_input\")\n",
    "        decoder_initial_states_inputs = [decoder_state_input_h]\n",
    "\n",
    "    # Getting layers from the trained model\n",
    "    dec_emb_layer_inf = training_model.get_layer(\"decoder_embedding\")\n",
    "    decoder_rnn_layer_inf = training_model.get_layer(f\"decoder_{config.cell_type}\") # Assumes single layer decoder for simplicity\n",
    "    attention_layer_inf = training_model.get_layer(\"attention_layer\") # Keras AdditiveAttention\n",
    "    decoder_dense_inf = training_model.get_layer(\"decoder_output_dense\")\n",
    "    concat_layer_inf = training_model.get_layer(\"concat_layer\")\n",
    "\n",
    "    # Decoder step execution\n",
    "    dec_emb_single_step = dec_emb_layer_inf(decoder_input_single_step) # Shape (batch, 1, embedding_dim)\n",
    "\n",
    "    # Decoder RNN step\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        decoder_rnn_output_step, state_h_dec, state_c_dec = decoder_rnn_layer_inf(\n",
    "            dec_emb_single_step, initial_state=decoder_initial_states_inputs\n",
    "        )\n",
    "        decoder_new_states = [state_h_dec, state_c_dec]\n",
    "    else: # GRU or SimpleRNN\n",
    "        decoder_rnn_output_step, state_h_dec = decoder_rnn_layer_inf(\n",
    "            dec_emb_single_step, initial_state=decoder_initial_states_inputs\n",
    "        )\n",
    "        decoder_new_states = [state_h_dec]\n",
    "    # decoder_rnn_output_step shape (batch, 1, decoder_hidden_size)\n",
    "    \n",
    "    # Attention step\n",
    "    # query is decoder_rnn_output_step, value is encoder_all_outputs_as_input\n",
    "    context_vector_step, attention_weights_step = attention_layer_inf(\n",
    "        [decoder_rnn_output_step, encoder_all_outputs_as_input], return_attention_scores=True\n",
    "    )\n",
    "    # context_vector_step shape: (batch, 1, encoder_hidden_size)\n",
    "    # attention_weights_step shape: (batch, 1, input_seq_len) (for AdditiveAttention)\n",
    "    # Squeeze out the time dimension from attention weights for plotting: (batch, input_seq_len)\n",
    "    squeezed_attention_weights = tf.squeeze(attention_weights_step, axis=1)\n",
    "\n",
    "\n",
    "    # Concatenate context vector with decoder RNN output for this step\n",
    "    decoder_concat_input_step = concat_layer_inf([decoder_rnn_output_step, context_vector_step])\n",
    "    # decoder_concat_input_step shape (batch, 1, combined_hidden_size)\n",
    "\n",
    "    # Final dense layer for this step\n",
    "    decoder_output_final_step = decoder_dense_inf(decoder_concat_input_step) # Shape (batch, 1, num_decoder_tokens)\n",
    "    # Squeezing out the time dimension for output probabilities\n",
    "    squeezed_decoder_output = tf.squeeze(decoder_output_final_step, axis=1)\n",
    "\n",
    "\n",
    "    decoder_model_inf = Model(\n",
    "        [decoder_input_single_step, encoder_all_outputs_as_input] + decoder_initial_states_inputs, \n",
    "        [squeezed_decoder_output, squeezed_attention_weights] + decoder_new_states\n",
    "    )\n",
    "    \n",
    "    return encoder_model_inf, decoder_model_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f68297-7831-41f7-8215-c4443da645d3",
   "metadata": {},
   "source": [
    "# Beam Search Decode Function for Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30101215-a6b1-43c6-b8dc-df779ff70c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_beam_search_attention(input_seq_vectorized, encoder_model, decoder_model, beam_width, config):\n",
    "    # Encoding the input to get all encoder outputs and final states\n",
    "    encoder_outputs = encoder_model.predict(input_seq_vectorized, verbose=0)\n",
    "    encoder_all_hidden_states = encoder_outputs[0] # This is the `values` for attention\n",
    "    \n",
    "    # Initial decoder states come from the rest of encoder_outputs\n",
    "    # If LSTM: [state_h, state_c], if GRU/RNN: [state_h]\n",
    "    initial_decoder_states = encoder_outputs[1:] \n",
    "\n",
    "    # Starting with the SOS token\n",
    "    start_token_idx = target_token_index[SOS_TOKEN]\n",
    "\n",
    "    initial_beam = [([start_token_idx], 0.0, initial_decoder_states, [])] \n",
    "    live_hypotheses = initial_beam\n",
    "\n",
    "    completed_hypotheses = []\n",
    "\n",
    "    for _ in range(max_decoder_seq_length): \n",
    "        new_hypotheses_candidates = []\n",
    "        \n",
    "        # If all live hypotheses have ended or no live hypotheses left\n",
    "        if not live_hypotheses or all(h[0][-1] == target_token_index[EOS_TOKEN] for h in live_hypotheses if len(h[0]) > 1):\n",
    "            break\n",
    "\n",
    "        for seq_indices, score, current_decoder_states, attn_weights_list in live_hypotheses:\n",
    "            # If EOS token is the last token, this hypothesis is complete\n",
    "            if seq_indices[-1] == target_token_index[EOS_TOKEN] and len(seq_indices) > 1:\n",
    "                completed_hypotheses.append((seq_indices, score / (len(seq_indices)-1), current_decoder_states, attn_weights_list)) # Normalize score\n",
    "                continue\n",
    "\n",
    "            # Preparing decoder input for the next step\n",
    "            last_token_idx_input = np.array([[seq_indices[-1]]])\n",
    "            \n",
    "            decoder_model_inputs = [last_token_idx_input, encoder_all_hidden_states] + current_decoder_states\n",
    "            \n",
    "            # Predicting next token probabilities, attention_weights, and new decoder states\n",
    "            decoder_pred_outputs = decoder_model.predict(decoder_model_inputs, verbose=0)\n",
    "            \n",
    "            output_token_probs = decoder_pred_outputs[0]      # Shape (batch=1, num_decoder_tokens)\n",
    "            attention_weights_step = decoder_pred_outputs[1]  # Shape (batch=1, input_seq_len)\n",
    "            new_decoder_states = decoder_pred_outputs[2:]     # List of state tensors\n",
    "\n",
    "            # Using log probabilities\n",
    "            log_probs = np.log(output_token_probs[0] + 1e-9) # Addng epsilon for stability\n",
    "            \n",
    "            # Getting top N candidates (N=beam_width)\n",
    "            top_k_indices = np.argsort(log_probs)[-beam_width:]\n",
    "            \n",
    "            for token_idx in top_k_indices:\n",
    "                new_seq_indices = seq_indices + [token_idx]\n",
    "                new_score = score + log_probs[token_idx]\n",
    "                new_attn_weights_list = attn_weights_list + [attention_weights_step[0]] # Store current step's attention\n",
    "                new_hypotheses_candidates.append((new_seq_indices, new_score, new_decoder_states, new_attn_weights_list))\n",
    "\n",
    "        # sorting\n",
    "        if new_hypotheses_candidates:\n",
    "            live_hypotheses = sorted(new_hypotheses_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        else:\n",
    "            live_hypotheses = [] \n",
    "\n",
    "    # Adding any remaining live hypotheses to completed (if they didn't end with EOS but max_len reached)\n",
    "    for seq_indices, score, states, attn_list in live_hypotheses:\n",
    "         completed_hypotheses.append((seq_indices, score / (len(seq_indices)-1) if len(seq_indices) > 1 else score, states, attn_list))\n",
    "\n",
    "    if not completed_hypotheses: # Handling cases where no hypothesis completes (e.g. very short max_decoder_seq_length)\n",
    "        if live_hypotheses:\n",
    "             best_hypothesis = max(live_hypotheses, key=lambda x: x[1]/len(x[0]) if len(x[0]) > 1 else x[1])\n",
    "        else:\n",
    "            return \"\", np.array([]) # Returning empty string and empty attention weights\n",
    "    else:\n",
    "        # Choosing the best hypothesis from completed ones (highest normalized score)\n",
    "        best_hypothesis = max(completed_hypotheses, key=lambda x: x[1])\n",
    "        \n",
    "    decoded_sentence_indices = best_hypothesis[0]\n",
    "    final_attention_weights_list = best_hypothesis[3] # List of attention arrays for each decoded step\n",
    "    \n",
    "    # Converting indices to characters\n",
    "    decoded_sentence = \"\"\n",
    "    for token_idx in decoded_sentence_indices:\n",
    "        if token_idx == target_token_index[SOS_TOKEN]:\n",
    "            continue\n",
    "        if token_idx == target_token_index[EOS_TOKEN]:\n",
    "            break\n",
    "        if token_idx in reverse_target_char_index:\n",
    "             decoded_sentence += reverse_target_char_index[token_idx]\n",
    "    \n",
    "    if final_attention_weights_list:\n",
    "        attention_matrix = np.array(final_attention_weights_list)\n",
    "        # Ensuring attention_matrix is 2D, e.g. (len_output_seq, len_input_seq)\n",
    "        if attention_matrix.ndim == 1: \n",
    "            attention_matrix = np.expand_dims(attention_matrix, axis=0)\n",
    "    else:\n",
    "        attention_matrix = np.array([]) \n",
    "\n",
    "    return decoded_sentence, attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd991ef-1420-4190-b5e1-a9f031602543",
   "metadata": {},
   "source": [
    "# Training and Evaluation Function for Sweep (train_evaluate_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b645291b-125c-48f3-a2d7-14adca6cfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_attention():\n",
    "    keras.backend.clear_session()\n",
    "    run = wandb.init() # Project/entity inherited from sweep\n",
    "    config = wandb.config\n",
    "\n",
    "    print(f\"--- Attention Model: Building model for run {run.id if run else 'N/A'} with config: {dict(config)} ---\")\n",
    "    attention_training_model = build_attention_seq2seq_model(config)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=config.early_stopping_patience, restore_best_weights=True, verbose=1)\n",
    "    wandb_metrics_logger = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "\n",
    "    print(f\"--- Attention Model: Starting training for run {run.id if run else 'N/A'} ---\")\n",
    "    history = attention_training_model.fit(\n",
    "        [encoder_input_train, decoder_input_train],\n",
    "        decoder_target_train,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs,\n",
    "        validation_data=([encoder_input_val, decoder_input_val], decoder_target_val),\n",
    "        callbacks=[early_stopping, wandb_metrics_logger],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    wandb.log({\"val_exact_match_accuracy_attention\": history.history['val_accuracy'][-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc1f7d-844b-4b10-b0c6-a2e392e115f1",
   "metadata": {},
   "source": [
    "# Wandb Sweep Configuration for Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f627cf-1dd8-49fb-a333-7ef58570d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_attention = {\n",
    "    'method': 'bayes',  # Bayesian optimization\n",
    "    'metric': {\n",
    "        'name': 'val_exact_match_accuracy_attention',\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'input_embedding_size': {\n",
    "            'values': [32, 64, 128] \n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [64, 128, 256] \n",
    "        },\n",
    "        'encoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'decoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['GRU', 'LSTM']\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'values': [0.2, 0.3]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'epochs': { \n",
    "            'values': [50] \n",
    "        },\n",
    "        'early_stopping_patience': {\n",
    "            'values': [5]\n",
    "        },\n",
    "        'beam_size': { \n",
    "            'values': [1, 3, 5] \n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'nadam']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6652e8-62b3-473e-a6ce-63e1254c7edc",
   "metadata": {},
   "source": [
    "# Start Sweep Agent for Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2416a-0e26-4e38-ae36-92a40f6be2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Initialize Sweep for Attention Model ---\n",
    "sweep_id_attention = wandb.sweep(\n",
    "    sweep_config_attention, \n",
    "    entity=\"ce21b097-indian-institute-of-technology-madras\", # Replace with your entity\n",
    "    project=\"CE21B097 - DA6401 - Assignment 3\" # Example: New project or tag runs\n",
    ")\n",
    "\n",
    "# --- Run Agent for Attention Model ---\n",
    "wandb.agent(sweep_id_attention, function=train_evaluate_attention, count=15)\n",
    "\n",
    "print(\"\\n--- Attention Model Sweep Finished ---\")\n",
    "print(\"Go to your W&B project page to see the results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa2dcc-a991-40fc-a52b-5b85fb5803fa",
   "metadata": {},
   "source": [
    "# (OR) directly evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf60b43-0157-468a-8ed6-8c34cbc9a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_attention = pd.read_csv(\"predictions_attention/test_predictions_attention.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17295c36-b000-49e2-8165-d7d5fdc63230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input (Roman)</th>\n",
       "      <th>Actual (Devanagari)</th>\n",
       "      <th>Predicted (Devanagari)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>have</td>\n",
       "      <td>हैव</td>\n",
       "      <td>हावे</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>hong</td>\n",
       "      <td>हॉन्ग</td>\n",
       "      <td>होंग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>half</td>\n",
       "      <td>हॉफ</td>\n",
       "      <td>हाल्फा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>hoaf</td>\n",
       "      <td>हॉफ</td>\n",
       "      <td>होफ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>hounga</td>\n",
       "      <td>होऊंगा</td>\n",
       "      <td>होंग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>holding</td>\n",
       "      <td>होल्डिंग</td>\n",
       "      <td>होल्डिंग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>hoshangabaad</td>\n",
       "      <td>होशंगाबाद</td>\n",
       "      <td>होशनागबाद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>hoshangabad</td>\n",
       "      <td>होशंगाबाद</td>\n",
       "      <td>होशनंगद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>hostes</td>\n",
       "      <td>होस्टेस</td>\n",
       "      <td>होस्टेस</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>hostess</td>\n",
       "      <td>होस्टेस</td>\n",
       "      <td>होस्टेस</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input (Roman) Actual (Devanagari) Predicted (Devanagari)\n",
       "4492          have                 हैव                   हावे\n",
       "4493          hong               हॉन्ग                   होंग\n",
       "4494          half                 हॉफ                 हाल्फा\n",
       "4495          hoaf                 हॉफ                    होफ\n",
       "4496        hounga              होऊंगा                   होंग\n",
       "4497       holding            होल्डिंग               होल्डिंग\n",
       "4498  hoshangabaad           होशंगाबाद              होशनागबाद\n",
       "4499   hoshangabad           होशंगाबाद                होशनंगद\n",
       "4500        hostes             होस्टेस                होस्टेस\n",
       "4501       hostess             होस्टेस                होस्टेस"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_attention.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff615ea-e983-4bb8-9e7e-b97f5df6cef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
