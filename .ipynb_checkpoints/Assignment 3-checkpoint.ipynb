{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f02508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Libraries (if not already installed)\n",
    "# !pip install wandb tensorflow numpy pandas scikit-learn\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras # Ensures keras is from tensorflow\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout # Removed Bidirectional, AdditiveAttention, Attention as not used in Q2 model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Removed ModelCheckpoint as WandbModelCheckpoint is used\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split # Not strictly used in the sweep, but good for general use\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111ab75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mce21b097\u001b[0m (\u001b[33mce21b097-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Wandb Login\n",
    "# Make sure to replace with your actual entity and project names in the sweep config later\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b52170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 44202\n",
      "Validation samples: 4358\n",
      "Test samples: 4502\n",
      "\n",
      "Sample training data:\n",
      "Input: an, Target: अं\n",
      "Input: ankganit, Target: अंकगणित\n",
      "Input: uncle, Target: अंकल\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Loading and Initial Parsing\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Loads data from a TSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t', header=None, on_bad_lines='skip', names=['native', 'roman', 'count'])\n",
    "        # The problem statement is romanized (input) to native (target)\n",
    "        # e.g., \"ajanabee अजनबी\" -> x = \"ajanabee\", y = \"अजनबी\"\n",
    "        # The Dakshina dataset lexicon format is: native_word, romanization, count\n",
    "        # So, for our task: input_texts = df['roman'], target_texts = df['native']\n",
    "        \n",
    "        # Handle cases where lines might not have 3 columns or have NaN values\n",
    "        df.dropna(subset=['native', 'roman'], inplace=True)\n",
    "        \n",
    "        input_texts = df['roman'].astype(str).tolist()\n",
    "        target_texts = df['native'].astype(str).tolist()\n",
    "        return input_texts, target_texts\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {filepath}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# --- Define file paths ---\n",
    "# Make sure these paths are correct for your local project structure\n",
    "# Assuming dakshina_dataset_v1.0 is in the same directory as the notebook\n",
    "dataset_base_dir = 'dakshina_dataset_v1.0' \n",
    "language = 'hi' # Hindi\n",
    "\n",
    "train_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.train.tsv')\n",
    "dev_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.dev.tsv')\n",
    "test_file = os.path.join(dataset_base_dir, language, 'lexicons', f'{language}.translit.sampled.test.tsv')\n",
    "\n",
    "# Load data\n",
    "input_texts_train_full, target_texts_train_full = load_data(train_file)\n",
    "input_texts_val, target_texts_val = load_data(dev_file)\n",
    "input_texts_test, target_texts_test = load_data(test_file) # Test set for final evaluation after sweep\n",
    "\n",
    "# For faster sweep iterations, you might want to use a subset of the training data\n",
    "# For now, let's use the full training data. If sweeps are too slow, consider sampling.\n",
    "input_texts_train, target_texts_train = input_texts_train_full, target_texts_train_full\n",
    "\n",
    "print(f\"Training samples: {len(input_texts_train)}\")\n",
    "print(f\"Validation samples: {len(input_texts_val)}\")\n",
    "print(f\"Test samples: {len(input_texts_test)}\")\n",
    "\n",
    "if len(input_texts_train) > 0 and len(target_texts_train) > 0:\n",
    "    print(\"\\nSample training data:\")\n",
    "    for i in range(min(3, len(input_texts_train))):\n",
    "        print(f\"Input: {input_texts_train[i]}, Target: {target_texts_train[i]}\")\n",
    "else:\n",
    "    print(\"No training data loaded. Please check file paths and content.\")\n",
    "\n",
    "if len(input_texts_val) == 0:\n",
    "    print(\"No validation data loaded. Sweeps will not work correctly without validation data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee76a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique input tokens: 26\n",
      "Number of unique output tokens: 65\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n",
      "\n",
      "Shape of encoder_input_train: (44202, 20)\n",
      "Shape of decoder_input_train: (44202, 21)\n",
      "Shape of decoder_target_train: (44202, 21, 65)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Preprocessing - Vocabulary, Tokenization, Padding\n",
    "\n",
    "# --- Character sets and tokenization ---\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for text in input_texts_train:\n",
    "    for char in text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "for text in target_texts_train:\n",
    "    for char in text: # Add SOS and EOS tokens\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "# Add special tokens\n",
    "SOS_TOKEN = '\\t' # Start Of Sequence\n",
    "EOS_TOKEN = '\\n' # End Of Sequence\n",
    "# Ensure target characters include SOS and EOS, even if not in training data explicitly for some reason\n",
    "target_characters.add(SOS_TOKEN)\n",
    "target_characters.add(EOS_TOKEN)\n",
    "\n",
    "\n",
    "input_char_list = sorted(list(input_characters))\n",
    "target_char_list = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_char_list)\n",
    "num_decoder_tokens = len(target_char_list)\n",
    "\n",
    "# Create char-to-index and index-to-char mappings\n",
    "input_token_index = {char: i for i, char in enumerate(input_char_list)}\n",
    "target_token_index = {char: i for i, char in enumerate(target_char_list)}\n",
    "\n",
    "reverse_input_char_index = {i: char for char, i in input_token_index.items()}\n",
    "reverse_target_char_index = {i: char for char, i in target_token_index.items()}\n",
    "\n",
    "# Determine max sequence lengths\n",
    "max_encoder_seq_length = max(len(text) for text in input_texts_train + input_texts_val)\n",
    "max_decoder_seq_length = max(len(text) for text in target_texts_train + target_texts_val) + 2 # +2 for SOS and EOS\n",
    "\n",
    "print(f\"\\nNumber of unique input tokens: {num_encoder_tokens}\")\n",
    "print(f\"Number of unique output tokens: {num_decoder_tokens}\")\n",
    "print(f\"Max sequence length for inputs: {max_encoder_seq_length}\")\n",
    "print(f\"Max sequence length for outputs: {max_decoder_seq_length}\")\n",
    "\n",
    "\n",
    "# --- Vectorize the data ---\n",
    "def vectorize_data(input_texts, target_texts, is_training=True):\n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\") # For sparse_categorical_crossentropy, this should be integers\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            if char in input_token_index: # Handle chars not in vocab if any (should not happen if vocab from train)\n",
    "                 encoder_input_data[i, t] = input_token_index[char]\n",
    "            # else: ignore unknown char or map to a special <UNK> token if defined\n",
    "        \n",
    "        # Decoder target data is ahead of decoder input data by one timestep\n",
    "        # and includes the start token.\n",
    "        # Decoder input: <SOS> char1 char2 ...\n",
    "        # Decoder target: char1 char2 ... <EOS>\n",
    "        \n",
    "        processed_target_text = SOS_TOKEN + target_text + EOS_TOKEN\n",
    "        for t, char in enumerate(processed_target_text):\n",
    "            if t < max_decoder_seq_length:\n",
    "                if char in target_token_index:\n",
    "                    decoder_input_data[i, t] = target_token_index[char]\n",
    "                    if t > 0: # decoder_target_data will be one timestep ahead\n",
    "                        # For sparse_categorical_crossentropy, target should be (batch, seq_len) with token indices\n",
    "                        # However, standard Keras examples use one-hot for TimeDistributed(Dense)\n",
    "                        # If using sparse_categorical_crossentropy, decoder_target_data should be integer indices\n",
    "                        decoder_target_data[i, t - 1, target_token_index[char]] = 1.0 # One-hot\n",
    "            # else: sequence is longer than max_decoder_seq_length, truncate\n",
    "    \n",
    "    # If using sparse_categorical_crossentropy, decoder_target_data should be:\n",
    "    # decoder_target_data_sparse = np.zeros((len(target_texts), max_decoder_seq_length), dtype=\"float32\")\n",
    "    # ... loop ...\n",
    "    # if t > 0 and char in target_token_index:\n",
    "    #    decoder_target_data_sparse[i, t-1] = target_token_index[char]\n",
    "    # return encoder_input_data, decoder_input_data, decoder_target_data_sparse\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "\n",
    "encoder_input_train, decoder_input_train, decoder_target_train = vectorize_data(input_texts_train, target_texts_train)\n",
    "encoder_input_val, decoder_input_val, decoder_target_val = vectorize_data(input_texts_val, target_texts_val)\n",
    "\n",
    "print(\"\\nShape of encoder_input_train:\", encoder_input_train.shape)\n",
    "print(\"Shape of decoder_input_train:\", decoder_input_train.shape)\n",
    "print(\"Shape of decoder_target_train:\", decoder_target_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdb2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Building Function\n",
    "\n",
    "def build_seq2seq_model(config):\n",
    "    \"\"\"Builds the Encoder-Decoder model based on wandb config.\"\"\"\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(None,), name=\"encoder_inputs\") # None allows variable sequence length for encoder input\n",
    "    emb_enc = Embedding(num_encoder_tokens, config.input_embedding_size, name=\"encoder_embedding\")(encoder_inputs)\n",
    "    \n",
    "    # Select RNN cell type\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        RNNCell = LSTM\n",
    "    elif config.cell_type == \"GRU\":\n",
    "        RNNCell = GRU\n",
    "    else: # Default to Vanilla RNN\n",
    "        RNNCell = keras.layers.SimpleRNN # Corrected SimpleRNN layer access\n",
    "\n",
    "    encoder_rnn_output = emb_enc\n",
    "    encoder_states_list = []\n",
    "\n",
    "    for i in range(config.encoder_layers):\n",
    "        is_last_layer = (i == config.encoder_layers - 1)\n",
    "        rnn_layer = RNNCell(config.hidden_size, \n",
    "                            return_sequences=not is_last_layer, # Only last layer returns just state\n",
    "                            return_state=True, \n",
    "                            dropout=config.dropout_rate if config.encoder_layers > 1 and i < config.encoder_layers-1 else 0.0, # Dropout between layers\n",
    "                            name=f\"encoder_{config.cell_type}_{i}\")\n",
    "        \n",
    "        if config.cell_type == \"LSTM\":\n",
    "            encoder_rnn_output, state_h, state_c = rnn_layer(encoder_rnn_output)\n",
    "            encoder_states = [state_h, state_c]\n",
    "        else: # GRU or SimpleRNN\n",
    "            encoder_rnn_output, state_h = rnn_layer(encoder_rnn_output)\n",
    "            encoder_states = [state_h]\n",
    "        \n",
    "        if is_last_layer: # We need the states from the last encoder layer for the decoder\n",
    "            encoder_states_list = encoder_states\n",
    "        else: # If intermediate layer, its output is sequence for next layer\n",
    "             encoder_rnn_output = Dropout(config.dropout_rate)(encoder_rnn_output) if config.dropout_rate > 0 else encoder_rnn_output\n",
    "\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
    "    # For decoder embedding, we can use a separate one or share with encoder if vocabularies were merged.\n",
    "    # Here, using a separate embedding layer for the decoder.\n",
    "    emb_dec = Embedding(num_decoder_tokens, config.input_embedding_size, name=\"decoder_embedding\")(decoder_inputs) # Using same embedding dim as input\n",
    "    \n",
    "    decoder_rnn_output = emb_dec\n",
    "    \n",
    "    for i in range(config.decoder_layers):\n",
    "        rnn_layer = RNNCell(config.hidden_size, \n",
    "                            return_sequences=True, \n",
    "                            return_state=True, \n",
    "                            dropout=config.dropout_rate if config.decoder_layers > 1 and i < config.decoder_layers-1 else 0.0,\n",
    "                            name=f\"decoder_{config.cell_type}_{i}\")\n",
    "        \n",
    "        # Initialize decoder with encoder's final states\n",
    "        # For the first decoder layer, initialize with encoder_states_list\n",
    "        # For subsequent decoder layers, they will initialize with their own previous states (Keras handles this)\n",
    "        initial_state_arg = encoder_states_list if i == 0 else None \n",
    "        \n",
    "        if config.cell_type == \"LSTM\":\n",
    "            decoder_rnn_output, _, _ = rnn_layer(decoder_rnn_output, initial_state=initial_state_arg)\n",
    "        else: # GRU or SimpleRNN\n",
    "            decoder_rnn_output, _ = rnn_layer(decoder_rnn_output, initial_state=initial_state_arg)\n",
    "        \n",
    "        if i < config.decoder_layers - 1: # Apply dropout between decoder layers\n",
    "             decoder_rnn_output = Dropout(config.dropout_rate)(decoder_rnn_output) if config.dropout_rate > 0 else decoder_rnn_output\n",
    "\n",
    "    # Final output layer\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\", name=\"decoder_output_dense\")\n",
    "    decoder_outputs = decoder_dense(decoder_rnn_output)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    # Optimizer can also be part of the sweep\n",
    "    optimizer_choice = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "    if hasattr(config, 'optimizer'):\n",
    "        if config.optimizer == 'rmsprop':\n",
    "            optimizer_choice = tf.keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n",
    "        elif config.optimizer == 'sgd':\n",
    "            optimizer_choice = tf.keras.optimizers.SGD(learning_rate=config.learning_rate)\n",
    "            \n",
    "    model.compile(optimizer=optimizer_choice, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # If decoder_target_data was integer indices, use \"sparse_categorical_crossentropy\"\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8f932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inference Models and Beam Search Decode Function\n",
    "\n",
    "def build_inference_models(training_model, config):\n",
    "    # --- Encoder Model for Inference ---\n",
    "    # Fix: Create Input layer instead of getting it from training model\n",
    "    encoder_inputs_inf = Input(shape=(None,), name=\"encoder_inputs_inf\") \n",
    "    \n",
    "    # Get encoder embedding layer output through the layer's weights\n",
    "    encoder_embedding_layer = training_model.get_layer(\"encoder_embedding\")\n",
    "    encoder_embedding_inf = encoder_embedding_layer(encoder_inputs_inf)\n",
    "    \n",
    "    current_encoder_output = encoder_embedding_inf\n",
    "    encoder_states_inf_list = []\n",
    "\n",
    "    # Rest of the encoder model building...\n",
    "    for i in range(config.encoder_layers):\n",
    "        encoder_rnn_layer_inf = training_model.get_layer(f\"encoder_{config.cell_type}_{i}\")\n",
    "        if config.cell_type == \"LSTM\":\n",
    "            current_encoder_output, state_h_enc, state_c_enc = encoder_rnn_layer_inf(current_encoder_output)\n",
    "            if i == config.encoder_layers - 1:\n",
    "                 encoder_states_inf_list = [state_h_enc, state_c_enc]\n",
    "        else: # GRU or SimpleRNN\n",
    "            current_encoder_output, state_h_enc = encoder_rnn_layer_inf(current_encoder_output)\n",
    "            if i == config.encoder_layers - 1:\n",
    "                encoder_states_inf_list = [state_h_enc]\n",
    "\n",
    "    # Create encoder model with the new input\n",
    "    encoder_model_inf = Model(encoder_inputs_inf, encoder_states_inf_list)\n",
    "    # --- Decoder Model for Inference ---\n",
    "    decoder_state_input_h_list = []\n",
    "    decoder_state_input_c_list = [] # Only for LSTM\n",
    "    decoder_states_inputs_inf_list = []\n",
    "\n",
    "    for i in range(config.decoder_layers):\n",
    "        state_h = Input(shape=(config.hidden_size,), name=f\"decoder_state_input_h_{i}\")\n",
    "        decoder_state_input_h_list.append(state_h)\n",
    "        decoder_states_inputs_inf_list.append(state_h)\n",
    "        if config.cell_type == \"LSTM\":\n",
    "            state_c = Input(shape=(config.hidden_size,), name=f\"decoder_state_input_c_{i}\")\n",
    "            decoder_state_input_c_list.append(state_c)\n",
    "            decoder_states_inputs_inf_list.append(state_c)\n",
    "\n",
    "\n",
    "    decoder_inputs_inf_single_step = Input(shape=(1,), name=\"decoder_inputs_single_step\") # Input is one char at a time\n",
    "    decoder_embedding_inf = training_model.get_layer(\"decoder_embedding\")(decoder_inputs_inf_single_step)\n",
    "\n",
    "    current_decoder_output_inf = decoder_embedding_inf\n",
    "    decoder_states_output_inf_list = []\n",
    "\n",
    "    # The initial states for the *first* decoder layer during inference come from the encoder.\n",
    "    # However, the inference decoder model needs to be general and accept states for *all its layers*.\n",
    "    # For the first step, we pass encoder_states to the first decoder layer.\n",
    "    # For subsequent steps, we pass the output states of the previous step.\n",
    "    \n",
    "    # We need to reconstruct the state inputs for each decoder layer carefully\n",
    "    # Keras layers expect a list of states if stateful, or if return_state=True\n",
    "    \n",
    "    temp_decoder_states_inputs_inf = []\n",
    "    if config.cell_type == \"LSTM\":\n",
    "        for i in range(config.decoder_layers):\n",
    "            temp_decoder_states_inputs_inf.extend([decoder_state_input_h_list[i], decoder_state_input_c_list[i]])\n",
    "    else: # GRU/SimpleRNN\n",
    "        for i in range(config.decoder_layers):\n",
    "            temp_decoder_states_inputs_inf.append(decoder_state_input_h_list[i])\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(config.decoder_layers):\n",
    "        decoder_rnn_layer_inf = training_model.get_layer(f\"decoder_{config.cell_type}_{i}\")\n",
    "        \n",
    "        # Prepare initial_state for this specific layer from the input states list\n",
    "        if config.cell_type == \"LSTM\":\n",
    "            layer_initial_states = [temp_decoder_states_inputs_inf[idx], temp_decoder_states_inputs_inf[idx+1]]\n",
    "            idx += 2\n",
    "            current_decoder_output_inf, state_h_dec, state_c_dec = decoder_rnn_layer_inf(\n",
    "                current_decoder_output_inf, initial_state=layer_initial_states\n",
    "            )\n",
    "            decoder_states_output_inf_list.extend([state_h_dec, state_c_dec])\n",
    "        else: # GRU or SimpleRNN\n",
    "            layer_initial_states = [temp_decoder_states_inputs_inf[idx]]\n",
    "            idx += 1\n",
    "            current_decoder_output_inf, state_h_dec = decoder_rnn_layer_inf(\n",
    "                current_decoder_output_inf, initial_state=layer_initial_states\n",
    "            )\n",
    "            decoder_states_output_inf_list.append(state_h_dec)\n",
    "            \n",
    "    decoder_dense_inf = training_model.get_layer(\"decoder_output_dense\")\n",
    "    decoder_outputs_inf = decoder_dense_inf(current_decoder_output_inf)\n",
    "    \n",
    "    decoder_model_inf = Model(\n",
    "        [decoder_inputs_inf_single_step] + temp_decoder_states_inputs_inf, \n",
    "        [decoder_outputs_inf] + decoder_states_output_inf_list\n",
    "    )\n",
    "    \n",
    "    return encoder_model_inf, decoder_model_inf\n",
    "\n",
    "\n",
    "def decode_sequence_beam_search(input_seq_vectorized, encoder_model, decoder_model, beam_width, config):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value_list = encoder_model.predict(input_seq_vectorized, verbose=0)\n",
    "    \n",
    "    if not isinstance(states_value_list, list):\n",
    "        states_value_list = [states_value_list]  # Convert to list if single state\n",
    "    \n",
    "    # Initialize decoder states\n",
    "    current_states_for_decoder_model = []\n",
    "    \n",
    "    # Populate initial states for the first decoder layer from encoder\n",
    "    current_states_for_decoder_model.extend(states_value_list)\n",
    "    \n",
    "    # Populate zero states for subsequent decoder layers (if any)\n",
    "    batch_size = 1  # For single sequence decoding\n",
    "    num_states_per_layer = 2 if config.cell_type == \"LSTM\" else 1\n",
    "    for _ in range(1, config.decoder_layers):\n",
    "        for _ in range(num_states_per_layer):\n",
    "            current_states_for_decoder_model.append(np.zeros((batch_size, config.hidden_size)))\n",
    "\n",
    "    # Start with the SOS token\n",
    "    target_seq = np.array([[target_token_index[SOS_TOKEN]]])\n",
    "    \n",
    "    # Initial beam: (sequence_indices, log_probability, states_for_decoder_model)\n",
    "    initial_beam = [([target_token_index[SOS_TOKEN]], 0.0, current_states_for_decoder_model)]\n",
    "    live_hypotheses = initial_beam\n",
    "\n",
    "    for _ in range(max_decoder_seq_length):\n",
    "        new_hypotheses = []\n",
    "        for seq_indices, score, current_states in live_hypotheses:\n",
    "            if seq_indices[-1] == target_token_index[EOS_TOKEN] and len(seq_indices) > 1:\n",
    "                new_hypotheses.append((seq_indices, score, current_states))\n",
    "                continue\n",
    "\n",
    "            # Predict next token\n",
    "            last_token_idx = np.array([[seq_indices[-1]]])\n",
    "            \n",
    "            # Make sure all inputs have batch_size=1 and correct shapes\n",
    "            decoder_model_inputs = [last_token_idx] + [\n",
    "                np.reshape(state, (1, -1)) if state.shape[0] != 1 else state \n",
    "                for state in current_states\n",
    "            ]\n",
    "            \n",
    "            output_tokens_probs_list = decoder_model.predict(decoder_model_inputs, verbose=0)\n",
    "            \n",
    "            output_tokens_probs = output_tokens_probs_list[0]  # Shape should be (1, 1, num_decoder_tokens)\n",
    "            new_states_list = output_tokens_probs_list[1:]\n",
    "\n",
    "            # Calculate log probabilities for all tokens\n",
    "            log_probs = np.log(output_tokens_probs[0, 0] + 1e-9)  # Get probabilities for the first (and only) timestep\n",
    "            top_k_indices = np.argsort(log_probs)[-beam_width:]  # Get indices of top k probabilities\n",
    "            \n",
    "            for token_idx in top_k_indices:\n",
    "                if token_idx < len(log_probs):  # Add bounds check\n",
    "                    new_seq_indices = seq_indices + [token_idx]\n",
    "                    new_score = score + log_probs[token_idx]\n",
    "                    new_hypotheses.append((new_seq_indices, new_score, new_states_list))\n",
    "\n",
    "        # Sort and keep top beam_width hypotheses\n",
    "        if new_hypotheses:  # Only sort if we have new hypotheses\n",
    "            live_hypotheses = sorted(new_hypotheses, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        else:\n",
    "            break  # No valid hypotheses, end decoding\n",
    "\n",
    "        if all(h[0][-1] == target_token_index[EOS_TOKEN] for h in live_hypotheses if len(h[0]) > 1):\n",
    "            break\n",
    "\n",
    "    # Choose best hypothesis and convert to text\n",
    "    if not live_hypotheses:  # Handle the case where we have no valid hypotheses\n",
    "        return \"\"\n",
    "        \n",
    "    best_hypothesis = max(live_hypotheses, key=lambda x: x[1]/len(x[0]) if len(x[0]) > 1 else x[1])\n",
    "    decoded_sentence_indices = best_hypothesis[0]\n",
    "    \n",
    "    decoded_sentence = \"\"\n",
    "    for token_idx in decoded_sentence_indices:\n",
    "        if token_idx == target_token_index[SOS_TOKEN]:\n",
    "            continue\n",
    "        if token_idx == target_token_index[EOS_TOKEN]:\n",
    "            break\n",
    "        if token_idx in reverse_target_char_index:\n",
    "             decoded_sentence += reverse_target_char_index[token_idx]\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70d932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training and Evaluation Function (train_evaluate) (Modified)\n",
    "from tqdm import tqdm\n",
    "def train_evaluate():\n",
    "    keras.backend.clear_session() # <<< --- ADD THIS LINE TO CLEAR KERAS SESSION\n",
    "    \n",
    "    # The agent (wandb.agent) calls this function.\n",
    "    # It sets up wandb.config. We initialize W&B to connect to this run.\n",
    "    run = wandb.init() # Project and entity are typically inherited from the sweep environment.\n",
    "                       \n",
    "    config = wandb.config # This is populated by the W&B agent\n",
    "\n",
    "    # Build the training model\n",
    "    print(f\"--- Building model for run {run.id if run else 'N/A'} with config: {dict(config)} ---\")\n",
    "    training_model = build_seq2seq_model(config)\n",
    "    # training_model.summary() # Optional: for debugging model structure\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                   patience=config.early_stopping_patience, \n",
    "                                   restore_best_weights=True, \n",
    "                                   verbose=1)\n",
    "    wandb_metrics_logger = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"--- Starting training for run {run.id if run else 'N/A'} ---\")\n",
    "    history = training_model.fit(\n",
    "        [encoder_input_train, decoder_input_train],\n",
    "        decoder_target_train,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs, \n",
    "        validation_data=([encoder_input_val, decoder_input_val], decoder_target_val),\n",
    "        callbacks=[early_stopping, wandb_metrics_logger],\n",
    "        verbose=1 \n",
    "    )\n",
    "    \n",
    "    wandb.log({\"val_exact_match_accuracy\": history.history['val_accuracy'][-1]})\n",
    "    # # --- Evaluation with Beam Search ---\n",
    "    # # Build inference models from the *trained* training_model weights\n",
    "    # print(f\"--- Building inference models for run {run.id if run else 'N/A'} ---\")\n",
    "    # encoder_model_inf, decoder_model_inf = build_inference_models(training_model, config)\n",
    "\n",
    "    # correct_predictions = 0\n",
    "    # total_predictions = encoder_input_val.shape[0] \n",
    "    \n",
    "    # if total_predictions == 0:\n",
    "    #     print(\"No validation data to evaluate.\")\n",
    "    #     wandb.log({\"val_exact_match_accuracy\": 0.0})\n",
    "    #     # wandb.finish() # Agent handles finishing the run\n",
    "    #     return\n",
    "\n",
    "    # eval_table_data = []\n",
    "    # print(f\"--- Starting evaluation for run {run.id if run else 'N/A'} ---\")\n",
    "    # for i in tqdm(range(total_predictions)):\n",
    "    #     current_input_vector = encoder_input_val[i:i+1] \n",
    "    #     original_input_text = input_texts_val[i] \n",
    "    #     original_target_text = target_texts_val[i]\n",
    "        \n",
    "    #     decoded_sentence = decode_sequence_beam_search(\n",
    "    #         current_input_vector, \n",
    "    #         encoder_model_inf, \n",
    "    #         decoder_model_inf, \n",
    "    #         config.beam_size,\n",
    "    #         config \n",
    "    #     )\n",
    "        \n",
    "    #     if decoded_sentence == original_target_text:\n",
    "    #         correct_predictions += 1\n",
    "            \n",
    "    #     if i < 5: \n",
    "    #         eval_table_data.append([original_input_text, original_target_text, decoded_sentence])\n",
    "\n",
    "    # if eval_table_data:\n",
    "    #     try: # Add try-except for wandb logging as a precaution\n",
    "    #         wandb.log({\"eval_examples\": wandb.Table(data=eval_table_data,\n",
    "    #                                                columns=[\"Input\", \"True Target\", \"Predicted Target\"])})\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error logging eval_examples to W&B: {e}\")\n",
    "\n",
    "\n",
    "    # val_exact_match_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0\n",
    "    \n",
    "    # try:\n",
    "    #     wandb.log({\"val_exact_match_accuracy\": val_exact_match_accuracy}) \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error logging val_exact_match_accuracy to W&B: {e}\")\n",
    "\n",
    "    \n",
    "    # print(f\"Run {run.id if run else 'Unknown'} | Validation Exact Match Accuracy (Beam Size {config.beam_size}): {val_exact_match_accuracy:.4f}\")\n",
    "    # print(f\"--- Finished evaluation for run {run.id if run else 'N/A'} ---\")\n",
    "    # # The W&B agent calling this function will handle wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e0aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Wandb Sweep Configuration\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',  # Bayesian optimization, or 'random', 'grid'\n",
    "    'metric': {\n",
    "        'name': 'val_exact_match_accuracy', # Custom metric from beam search eval\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'input_embedding_size': {\n",
    "            'values': [32, 64, 128] \n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [64, 128, 256] \n",
    "        },\n",
    "        'encoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'decoder_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'GRU', 'LSTM']\n",
    "        },\n",
    "        'dropout_rate': {\n",
    "            'values': [0.2, 0.3]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001, 0.0001]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64, 128, 356]\n",
    "        },\n",
    "        'epochs': { # Max epochs, early stopping will handle actual duration\n",
    "            'values': [50] # Reduced for quicker sweep, increase for final model\n",
    "        },\n",
    "        'early_stopping_patience': {\n",
    "            'values': [5]\n",
    "        },\n",
    "        'beam_size': { # This is for evaluation\n",
    "            'values': [1, 3, 5] # 1 is greedy\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'nadam']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add a note about sweep strategy:\n",
    "# Smart strategies:\n",
    "# 1. Bayesian optimization (`method: 'bayes'`) is generally more efficient than random or grid search.\n",
    "# 2. Early Stopping: Already implemented to stop unpromising runs early, saving compute.\n",
    "# 3. Iterative Sweeps: Start with broader ranges and fewer epochs/smaller dataset subset.\n",
    "#    Analyze results (parallel coordinates, correlation plots from W&B) to identify promising regions.\n",
    "#    Then, conduct a more focused sweep with narrowed ranges, more epochs, or the full dataset.\n",
    "#    (For this assignment, a single comprehensive sweep as configured might be sufficient if time permits,\n",
    "#     otherwise, reduce `epochs` or `count` for the agent initially).\n",
    "# 4. Prioritize parameters: Learning rate, cell type, and hidden size are often critical.\n",
    "#    Dropout and number of layers can be fine-tuned once a good base is found.\n",
    "# 5. Reduce `count` for `wandb.agent` for initial testing of the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e17575c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "942f835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: a9aclnzc\n",
      "Sweep URL: https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ysiqu3z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_131639-0ysiqu3z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/0ysiqu3z' target=\"_blank\">decent-sweep-1</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/0ysiqu3z' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/0ysiqu3z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run 0ysiqu3z with config: {'batch_size': 128, 'beam_size': 3, 'cell_type': 'GRU', 'decoder_layers': 2, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 128, 'learning_rate': 0.001, 'optimizer': 'adam'} ---\n",
      "--- Starting training for run 0ysiqu3z ---\n",
      "Epoch 1/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 60ms/step - accuracy: 0.0692 - loss: 1.2046 - val_accuracy: 0.0787 - val_loss: 1.0016\n",
      "Epoch 2/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.0861 - loss: 1.0232 - val_accuracy: 0.0942 - val_loss: 0.9222\n",
      "Epoch 3/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.1036 - loss: 0.9480 - val_accuracy: 0.1047 - val_loss: 0.8651\n",
      "Epoch 4/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.1149 - loss: 0.8913 - val_accuracy: 0.1200 - val_loss: 0.8010\n",
      "Epoch 5/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.1275 - loss: 0.8317 - val_accuracy: 0.1309 - val_loss: 0.7497\n",
      "Epoch 6/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.1399 - loss: 0.7832 - val_accuracy: 0.1481 - val_loss: 0.6940\n",
      "Epoch 7/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.1535 - loss: 0.7330 - val_accuracy: 0.1596 - val_loss: 0.6426\n",
      "Epoch 8/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.1646 - loss: 0.6859 - val_accuracy: 0.1696 - val_loss: 0.5994\n",
      "Epoch 9/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.1748 - loss: 0.6399 - val_accuracy: 0.1837 - val_loss: 0.5493\n",
      "Epoch 10/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.1862 - loss: 0.5987 - val_accuracy: 0.1938 - val_loss: 0.5135\n",
      "Epoch 11/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.1952 - loss: 0.5653 - val_accuracy: 0.2041 - val_loss: 0.4806\n",
      "Epoch 12/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.2025 - loss: 0.5392 - val_accuracy: 0.2094 - val_loss: 0.4555\n",
      "Epoch 13/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2092 - loss: 0.5123 - val_accuracy: 0.2157 - val_loss: 0.4325\n",
      "Epoch 14/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.2143 - loss: 0.4915 - val_accuracy: 0.2210 - val_loss: 0.4128\n",
      "Epoch 15/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2205 - loss: 0.4724 - val_accuracy: 0.2253 - val_loss: 0.3970\n",
      "Epoch 16/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.2239 - loss: 0.4571 - val_accuracy: 0.2288 - val_loss: 0.3850\n",
      "Epoch 17/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2278 - loss: 0.4428 - val_accuracy: 0.2329 - val_loss: 0.3704\n",
      "Epoch 18/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2308 - loss: 0.4327 - val_accuracy: 0.2363 - val_loss: 0.3602\n",
      "Epoch 19/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2340 - loss: 0.4221 - val_accuracy: 0.2378 - val_loss: 0.3512\n",
      "Epoch 20/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2373 - loss: 0.4121 - val_accuracy: 0.2405 - val_loss: 0.3427\n",
      "Epoch 21/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2391 - loss: 0.4034 - val_accuracy: 0.2416 - val_loss: 0.3357\n",
      "Epoch 22/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2410 - loss: 0.3955 - val_accuracy: 0.2434 - val_loss: 0.3307\n",
      "Epoch 23/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2436 - loss: 0.3865 - val_accuracy: 0.2451 - val_loss: 0.3242\n",
      "Epoch 24/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2455 - loss: 0.3799 - val_accuracy: 0.2462 - val_loss: 0.3184\n",
      "Epoch 25/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2462 - loss: 0.3767 - val_accuracy: 0.2473 - val_loss: 0.3150\n",
      "Epoch 26/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2478 - loss: 0.3707 - val_accuracy: 0.2485 - val_loss: 0.3086\n",
      "Epoch 27/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2495 - loss: 0.3645 - val_accuracy: 0.2492 - val_loss: 0.3061\n",
      "Epoch 28/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2519 - loss: 0.3615 - val_accuracy: 0.2498 - val_loss: 0.3017\n",
      "Epoch 29/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.2521 - loss: 0.3537 - val_accuracy: 0.2510 - val_loss: 0.2979\n",
      "Epoch 30/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2525 - loss: 0.3525 - val_accuracy: 0.2511 - val_loss: 0.2958\n",
      "Epoch 31/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2532 - loss: 0.3479 - val_accuracy: 0.2521 - val_loss: 0.2932\n",
      "Epoch 32/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2549 - loss: 0.3417 - val_accuracy: 0.2538 - val_loss: 0.2895\n",
      "Epoch 33/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2560 - loss: 0.3407 - val_accuracy: 0.2538 - val_loss: 0.2877\n",
      "Epoch 34/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2565 - loss: 0.3386 - val_accuracy: 0.2539 - val_loss: 0.2866\n",
      "Epoch 35/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2573 - loss: 0.3353 - val_accuracy: 0.2552 - val_loss: 0.2829\n",
      "Epoch 36/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2582 - loss: 0.3326 - val_accuracy: 0.2547 - val_loss: 0.2832\n",
      "Epoch 37/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2591 - loss: 0.3301 - val_accuracy: 0.2549 - val_loss: 0.2814\n",
      "Epoch 38/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2592 - loss: 0.3249 - val_accuracy: 0.2556 - val_loss: 0.2792\n",
      "Epoch 39/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2598 - loss: 0.3236 - val_accuracy: 0.2559 - val_loss: 0.2775\n",
      "Epoch 40/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2609 - loss: 0.3204 - val_accuracy: 0.2570 - val_loss: 0.2738\n",
      "Epoch 41/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2609 - loss: 0.3198 - val_accuracy: 0.2568 - val_loss: 0.2735\n",
      "Epoch 42/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2621 - loss: 0.3176 - val_accuracy: 0.2571 - val_loss: 0.2713\n",
      "Epoch 43/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2622 - loss: 0.3150 - val_accuracy: 0.2581 - val_loss: 0.2699\n",
      "Epoch 44/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2629 - loss: 0.3115 - val_accuracy: 0.2575 - val_loss: 0.2696\n",
      "Epoch 45/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2631 - loss: 0.3143 - val_accuracy: 0.2586 - val_loss: 0.2674\n",
      "Epoch 46/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2640 - loss: 0.3114 - val_accuracy: 0.2583 - val_loss: 0.2661\n",
      "Epoch 47/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2643 - loss: 0.3081 - val_accuracy: 0.2588 - val_loss: 0.2645\n",
      "Epoch 48/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2647 - loss: 0.3052 - val_accuracy: 0.2585 - val_loss: 0.2641\n",
      "Epoch 49/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2646 - loss: 0.3041 - val_accuracy: 0.2588 - val_loss: 0.2667\n",
      "Epoch 50/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2653 - loss: 0.3017 - val_accuracy: 0.2602 - val_loss: 0.2603\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▂▃▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.26523</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.30303</td></tr><tr><td>epoch/val_accuracy</td><td>0.26017</td></tr><tr><td>epoch/val_loss</td><td>0.26034</td></tr><tr><td>val_exact_match_accuracy</td><td>0.26017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-sweep-1</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/0ysiqu3z' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/0ysiqu3z</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_131639-0ysiqu3z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: btvjpe57 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_133407-btvjpe57</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/btvjpe57' target=\"_blank\">stilted-sweep-2</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/btvjpe57' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/btvjpe57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run btvjpe57 with config: {'batch_size': 64, 'beam_size': 5, 'cell_type': 'LSTM', 'decoder_layers': 2, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 32, 'learning_rate': 0.0001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run btvjpe57 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.0463 - loss: 1.3440 - val_accuracy: 0.0650 - val_loss: 1.1780\n",
      "Epoch 2/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.0664 - loss: 1.2218 - val_accuracy: 0.0683 - val_loss: 1.1481\n",
      "Epoch 3/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0712 - loss: 1.1944 - val_accuracy: 0.0710 - val_loss: 1.1320\n",
      "Epoch 4/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0739 - loss: 1.1786 - val_accuracy: 0.0717 - val_loss: 1.1244\n",
      "Epoch 5/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0766 - loss: 1.1672 - val_accuracy: 0.0755 - val_loss: 1.1131\n",
      "Epoch 6/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0792 - loss: 1.1584 - val_accuracy: 0.0768 - val_loss: 1.1000\n",
      "Epoch 7/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.0815 - loss: 1.1457 - val_accuracy: 0.0781 - val_loss: 1.0956\n",
      "Epoch 8/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0842 - loss: 1.1360 - val_accuracy: 0.0808 - val_loss: 1.0859\n",
      "Epoch 9/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.0866 - loss: 1.1287 - val_accuracy: 0.0814 - val_loss: 1.0803\n",
      "Epoch 10/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.0881 - loss: 1.1226 - val_accuracy: 0.0821 - val_loss: 1.0737\n",
      "Epoch 11/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.0885 - loss: 1.1120 - val_accuracy: 0.0828 - val_loss: 1.0687\n",
      "Epoch 12/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.0905 - loss: 1.1071 - val_accuracy: 0.0850 - val_loss: 1.0517\n",
      "Epoch 13/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.0913 - loss: 1.0953 - val_accuracy: 0.0857 - val_loss: 1.0487\n",
      "Epoch 14/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.0926 - loss: 1.0846 - val_accuracy: 0.0870 - val_loss: 1.0347\n",
      "Epoch 15/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.0924 - loss: 1.0761 - val_accuracy: 0.0879 - val_loss: 1.0266\n",
      "Epoch 16/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.0938 - loss: 1.0682 - val_accuracy: 0.0894 - val_loss: 1.0113\n",
      "Epoch 17/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.0946 - loss: 1.0497 - val_accuracy: 0.0909 - val_loss: 0.9925\n",
      "Epoch 18/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.0959 - loss: 1.0355 - val_accuracy: 0.0918 - val_loss: 0.9856\n",
      "Epoch 19/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.0984 - loss: 1.0265 - val_accuracy: 0.0939 - val_loss: 0.9752\n",
      "Epoch 20/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.0994 - loss: 1.0151 - val_accuracy: 0.0949 - val_loss: 0.9667\n",
      "Epoch 21/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1001 - loss: 1.0082 - val_accuracy: 0.0963 - val_loss: 0.9592\n",
      "Epoch 22/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1018 - loss: 1.0013 - val_accuracy: 0.0976 - val_loss: 0.9534\n",
      "Epoch 23/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1030 - loss: 0.9971 - val_accuracy: 0.0986 - val_loss: 0.9488\n",
      "Epoch 24/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1039 - loss: 0.9887 - val_accuracy: 0.0998 - val_loss: 0.9442\n",
      "Epoch 25/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1048 - loss: 0.9848 - val_accuracy: 0.1009 - val_loss: 0.9376\n",
      "Epoch 26/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1051 - loss: 0.9820 - val_accuracy: 0.1015 - val_loss: 0.9353\n",
      "Epoch 27/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.1063 - loss: 0.9778 - val_accuracy: 0.1018 - val_loss: 0.9306\n",
      "Epoch 28/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1066 - loss: 0.9703 - val_accuracy: 0.1025 - val_loss: 0.9250\n",
      "Epoch 29/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1073 - loss: 0.9665 - val_accuracy: 0.1036 - val_loss: 0.9224\n",
      "Epoch 30/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1085 - loss: 0.9639 - val_accuracy: 0.1039 - val_loss: 0.9191\n",
      "Epoch 31/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1087 - loss: 0.9599 - val_accuracy: 0.1050 - val_loss: 0.9156\n",
      "Epoch 32/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1094 - loss: 0.9583 - val_accuracy: 0.1052 - val_loss: 0.9124\n",
      "Epoch 33/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1099 - loss: 0.9547 - val_accuracy: 0.1064 - val_loss: 0.9088\n",
      "Epoch 34/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1109 - loss: 0.9528 - val_accuracy: 0.1072 - val_loss: 0.9062\n",
      "Epoch 35/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1116 - loss: 0.9476 - val_accuracy: 0.1072 - val_loss: 0.9047\n",
      "Epoch 36/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1114 - loss: 0.9448 - val_accuracy: 0.1083 - val_loss: 0.9005\n",
      "Epoch 37/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1130 - loss: 0.9440 - val_accuracy: 0.1089 - val_loss: 0.8982\n",
      "Epoch 38/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1136 - loss: 0.9361 - val_accuracy: 0.1106 - val_loss: 0.8928\n",
      "Epoch 39/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1140 - loss: 0.9334 - val_accuracy: 0.1113 - val_loss: 0.8903\n",
      "Epoch 40/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1149 - loss: 0.9339 - val_accuracy: 0.1126 - val_loss: 0.8877\n",
      "Epoch 41/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1159 - loss: 0.9302 - val_accuracy: 0.1134 - val_loss: 0.8850\n",
      "Epoch 42/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1166 - loss: 0.9286 - val_accuracy: 0.1143 - val_loss: 0.8811\n",
      "Epoch 43/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1171 - loss: 0.9237 - val_accuracy: 0.1148 - val_loss: 0.8789\n",
      "Epoch 44/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1173 - loss: 0.9204 - val_accuracy: 0.1151 - val_loss: 0.8779\n",
      "Epoch 45/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1192 - loss: 0.9182 - val_accuracy: 0.1162 - val_loss: 0.8737\n",
      "Epoch 46/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1192 - loss: 0.9157 - val_accuracy: 0.1169 - val_loss: 0.8683\n",
      "Epoch 47/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 36ms/step - accuracy: 0.1204 - loss: 0.9103 - val_accuracy: 0.1177 - val_loss: 0.8654\n",
      "Epoch 48/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.1210 - loss: 0.9070 - val_accuracy: 0.1181 - val_loss: 0.8626\n",
      "Epoch 49/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.1214 - loss: 0.9032 - val_accuracy: 0.1179 - val_loss: 0.8607\n",
      "Epoch 50/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.1219 - loss: 0.9032 - val_accuracy: 0.1189 - val_loss: 0.8584\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.12234</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.90264</td></tr><tr><td>epoch/val_accuracy</td><td>0.11887</td></tr><tr><td>epoch/val_loss</td><td>0.85844</td></tr><tr><td>val_exact_match_accuracy</td><td>0.11887</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-2</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/btvjpe57' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/btvjpe57</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_133407-btvjpe57\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lqzsvpbj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_135302-lqzsvpbj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/lqzsvpbj' target=\"_blank\">floral-sweep-3</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/lqzsvpbj' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/lqzsvpbj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run lqzsvpbj with config: {'batch_size': 64, 'beam_size': 5, 'cell_type': 'RNN', 'decoder_layers': 1, 'dropout_rate': 0.3, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 256, 'input_embedding_size': 128, 'learning_rate': 0.0001, 'optimizer': 'adam'} ---\n",
      "--- Starting training for run lqzsvpbj ---\n",
      "Epoch 1/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.0717 - loss: 1.2193 - val_accuracy: 0.0919 - val_loss: 1.0769\n",
      "Epoch 2/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.0979 - loss: 1.1070 - val_accuracy: 0.1056 - val_loss: 0.9511\n",
      "Epoch 3/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1106 - loss: 0.9793 - val_accuracy: 0.1145 - val_loss: 0.8683\n",
      "Epoch 4/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1215 - loss: 0.9031 - val_accuracy: 0.1249 - val_loss: 0.8163\n",
      "Epoch 5/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.1310 - loss: 0.8548 - val_accuracy: 0.1125 - val_loss: 0.8719\n",
      "Epoch 6/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.1237 - loss: 0.8790 - val_accuracy: 0.1305 - val_loss: 0.7925\n",
      "Epoch 7/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1361 - loss: 0.8284 - val_accuracy: 0.1353 - val_loss: 0.7689\n",
      "Epoch 8/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.1412 - loss: 0.8079 - val_accuracy: 0.1264 - val_loss: 0.8018\n",
      "Epoch 9/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.1378 - loss: 0.8155 - val_accuracy: 0.1391 - val_loss: 0.7454\n",
      "Epoch 10/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.1448 - loss: 0.7832 - val_accuracy: 0.1434 - val_loss: 0.7268\n",
      "Epoch 11/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1472 - loss: 0.7659 - val_accuracy: 0.1435 - val_loss: 0.7288\n",
      "Epoch 12/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1489 - loss: 0.7634 - val_accuracy: 0.1462 - val_loss: 0.7133\n",
      "Epoch 13/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.1531 - loss: 0.7465 - val_accuracy: 0.1501 - val_loss: 0.6913\n",
      "Epoch 14/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.1554 - loss: 0.7312 - val_accuracy: 0.1503 - val_loss: 0.6948\n",
      "Epoch 15/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1500 - loss: 0.7545 - val_accuracy: 0.1438 - val_loss: 0.7214\n",
      "Epoch 16/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1507 - loss: 0.7578 - val_accuracy: 0.1483 - val_loss: 0.6971\n",
      "Epoch 17/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.1541 - loss: 0.7332 - val_accuracy: 0.1509 - val_loss: 0.6857\n",
      "Epoch 18/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1540 - loss: 0.7367 - val_accuracy: 0.1511 - val_loss: 0.6859\n",
      "Epoch 19/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1570 - loss: 0.7255 - val_accuracy: 0.1536 - val_loss: 0.6754\n",
      "Epoch 20/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1597 - loss: 0.7148 - val_accuracy: 0.1562 - val_loss: 0.6651\n",
      "Epoch 21/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1596 - loss: 0.7098 - val_accuracy: 0.1575 - val_loss: 0.6601\n",
      "Epoch 22/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1625 - loss: 0.6980 - val_accuracy: 0.1590 - val_loss: 0.6502\n",
      "Epoch 23/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.1640 - loss: 0.6879 - val_accuracy: 0.1612 - val_loss: 0.6405\n",
      "Epoch 24/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1666 - loss: 0.6824 - val_accuracy: 0.1633 - val_loss: 0.6311\n",
      "Epoch 25/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1667 - loss: 0.6760 - val_accuracy: 0.1642 - val_loss: 0.6261\n",
      "Epoch 26/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1689 - loss: 0.6671 - val_accuracy: 0.1586 - val_loss: 0.6517\n",
      "Epoch 27/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1665 - loss: 0.6762 - val_accuracy: 0.1654 - val_loss: 0.6173\n",
      "Epoch 28/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.1719 - loss: 0.6500 - val_accuracy: 0.1689 - val_loss: 0.6062\n",
      "Epoch 29/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1721 - loss: 0.6501 - val_accuracy: 0.1688 - val_loss: 0.6033\n",
      "Epoch 30/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1753 - loss: 0.6388 - val_accuracy: 0.1568 - val_loss: 0.6466\n",
      "Epoch 31/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1712 - loss: 0.6507 - val_accuracy: 0.1710 - val_loss: 0.5911\n",
      "Epoch 32/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1775 - loss: 0.6262 - val_accuracy: 0.1733 - val_loss: 0.5821\n",
      "Epoch 33/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1798 - loss: 0.6163 - val_accuracy: 0.1550 - val_loss: 0.6567\n",
      "Epoch 34/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1764 - loss: 0.6278 - val_accuracy: 0.1773 - val_loss: 0.5693\n",
      "Epoch 35/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1825 - loss: 0.6026 - val_accuracy: 0.1794 - val_loss: 0.5622\n",
      "Epoch 36/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.1838 - loss: 0.5951 - val_accuracy: 0.1810 - val_loss: 0.5555\n",
      "Epoch 37/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.1860 - loss: 0.5853 - val_accuracy: 0.1819 - val_loss: 0.5489\n",
      "Epoch 38/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.1822 - loss: 0.6059 - val_accuracy: 0.1820 - val_loss: 0.5511\n",
      "Epoch 39/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.1879 - loss: 0.5839 - val_accuracy: 0.1846 - val_loss: 0.5401\n",
      "Epoch 40/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.1899 - loss: 0.5709 - val_accuracy: 0.1863 - val_loss: 0.5336\n",
      "Epoch 41/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1919 - loss: 0.5640 - val_accuracy: 0.1866 - val_loss: 0.5287\n",
      "Epoch 42/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1934 - loss: 0.5598 - val_accuracy: 0.1815 - val_loss: 0.5517\n",
      "Epoch 43/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1836 - loss: 0.5955 - val_accuracy: 0.1904 - val_loss: 0.5211\n",
      "Epoch 44/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1859 - loss: 0.5900 - val_accuracy: 0.1842 - val_loss: 0.5422\n",
      "Epoch 45/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1903 - loss: 0.5691 - val_accuracy: 0.1899 - val_loss: 0.5227\n",
      "Epoch 46/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.1946 - loss: 0.5525 - val_accuracy: 0.1914 - val_loss: 0.5147\n",
      "Epoch 47/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 36ms/step - accuracy: 0.1953 - loss: 0.5497 - val_accuracy: 0.1889 - val_loss: 0.5203\n",
      "Epoch 48/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.1962 - loss: 0.5473 - val_accuracy: 0.1938 - val_loss: 0.5076\n",
      "Epoch 49/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.1986 - loss: 0.5364 - val_accuracy: 0.1936 - val_loss: 0.5028\n",
      "Epoch 50/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.1938 - loss: 0.5522 - val_accuracy: 0.1941 - val_loss: 0.5042\n",
      "Restoring model weights from the end of the best epoch: 49.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████▇████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▃▃▄▃▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▅▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>epoch/val_loss</td><td>█▆▅▅▅▄▅▄▄▄▃▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.19398</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.55314</td></tr><tr><td>epoch/val_accuracy</td><td>0.19414</td></tr><tr><td>epoch/val_loss</td><td>0.50421</td></tr><tr><td>val_exact_match_accuracy</td><td>0.19414</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-sweep-3</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/lqzsvpbj' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/lqzsvpbj</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_135302-lqzsvpbj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h6vwylba with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_141058-h6vwylba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/h6vwylba' target=\"_blank\">solar-sweep-4</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/h6vwylba' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/h6vwylba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run h6vwylba with config: {'batch_size': 64, 'beam_size': 3, 'cell_type': 'RNN', 'decoder_layers': 1, 'dropout_rate': 0.3, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 64, 'learning_rate': 0.0001, 'optimizer': 'adam'} ---\n",
      "--- Starting training for run h6vwylba ---\n",
      "Epoch 1/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.0454 - loss: 1.3413 - val_accuracy: 0.0725 - val_loss: 1.1234\n",
      "Epoch 2/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.0769 - loss: 1.1633 - val_accuracy: 0.0814 - val_loss: 1.0797\n",
      "Epoch 3/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.0837 - loss: 1.1227 - val_accuracy: 0.0852 - val_loss: 1.0512\n",
      "Epoch 4/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.0880 - loss: 1.0934 - val_accuracy: 0.0888 - val_loss: 1.0255\n",
      "Epoch 5/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.0930 - loss: 1.0688 - val_accuracy: 0.0939 - val_loss: 0.9998\n",
      "Epoch 6/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.0976 - loss: 1.0436 - val_accuracy: 0.0981 - val_loss: 0.9821\n",
      "Epoch 7/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1024 - loss: 1.0278 - val_accuracy: 0.1019 - val_loss: 0.9657\n",
      "Epoch 8/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1042 - loss: 1.0123 - val_accuracy: 0.1043 - val_loss: 0.9527\n",
      "Epoch 9/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1089 - loss: 0.9929 - val_accuracy: 0.1064 - val_loss: 0.9393\n",
      "Epoch 10/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1109 - loss: 0.9816 - val_accuracy: 0.1088 - val_loss: 0.9268\n",
      "Epoch 11/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1134 - loss: 0.9657 - val_accuracy: 0.1108 - val_loss: 0.9155\n",
      "Epoch 12/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1157 - loss: 0.9538 - val_accuracy: 0.1118 - val_loss: 0.9055\n",
      "Epoch 13/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1172 - loss: 0.9419 - val_accuracy: 0.1127 - val_loss: 0.8964\n",
      "Epoch 14/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1190 - loss: 0.9337 - val_accuracy: 0.1138 - val_loss: 0.8863\n",
      "Epoch 15/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1200 - loss: 0.9274 - val_accuracy: 0.1149 - val_loss: 0.8789\n",
      "Epoch 16/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1214 - loss: 0.9162 - val_accuracy: 0.1161 - val_loss: 0.8721\n",
      "Epoch 17/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1222 - loss: 0.9108 - val_accuracy: 0.1171 - val_loss: 0.8657\n",
      "Epoch 18/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1234 - loss: 0.9027 - val_accuracy: 0.1172 - val_loss: 0.8608\n",
      "Epoch 19/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1240 - loss: 0.8991 - val_accuracy: 0.1182 - val_loss: 0.8564\n",
      "Epoch 20/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1252 - loss: 0.8931 - val_accuracy: 0.1204 - val_loss: 0.8494\n",
      "Epoch 21/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.1251 - loss: 0.8900 - val_accuracy: 0.1193 - val_loss: 0.8513\n",
      "Epoch 22/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.1258 - loss: 0.8869 - val_accuracy: 0.1205 - val_loss: 0.8440\n",
      "Epoch 23/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1265 - loss: 0.8802 - val_accuracy: 0.1218 - val_loss: 0.8400\n",
      "Epoch 24/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1273 - loss: 0.8772 - val_accuracy: 0.1220 - val_loss: 0.8368\n",
      "Epoch 25/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1279 - loss: 0.8750 - val_accuracy: 0.1229 - val_loss: 0.8347\n",
      "Epoch 26/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1294 - loss: 0.8724 - val_accuracy: 0.1231 - val_loss: 0.8311\n",
      "Epoch 27/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1291 - loss: 0.8710 - val_accuracy: 0.1241 - val_loss: 0.8282\n",
      "Epoch 28/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1301 - loss: 0.8674 - val_accuracy: 0.1246 - val_loss: 0.8273\n",
      "Epoch 29/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1311 - loss: 0.8643 - val_accuracy: 0.1262 - val_loss: 0.8220\n",
      "Epoch 30/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.1317 - loss: 0.8581 - val_accuracy: 0.1274 - val_loss: 0.8185\n",
      "Epoch 31/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1324 - loss: 0.8581 - val_accuracy: 0.1283 - val_loss: 0.8159\n",
      "Epoch 32/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1333 - loss: 0.8547 - val_accuracy: 0.1290 - val_loss: 0.8132\n",
      "Epoch 33/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1338 - loss: 0.8506 - val_accuracy: 0.1294 - val_loss: 0.8096\n",
      "Epoch 34/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1350 - loss: 0.8498 - val_accuracy: 0.1304 - val_loss: 0.8074\n",
      "Epoch 35/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1354 - loss: 0.8432 - val_accuracy: 0.1300 - val_loss: 0.8075\n",
      "Epoch 36/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1358 - loss: 0.8423 - val_accuracy: 0.1309 - val_loss: 0.8030\n",
      "Epoch 37/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1364 - loss: 0.8422 - val_accuracy: 0.1319 - val_loss: 0.8015\n",
      "Epoch 38/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1373 - loss: 0.8388 - val_accuracy: 0.1324 - val_loss: 0.7981\n",
      "Epoch 39/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1378 - loss: 0.8362 - val_accuracy: 0.1323 - val_loss: 0.7974\n",
      "Epoch 40/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1384 - loss: 0.8363 - val_accuracy: 0.1328 - val_loss: 0.7952\n",
      "Epoch 41/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1387 - loss: 0.8340 - val_accuracy: 0.1330 - val_loss: 0.7923\n",
      "Epoch 42/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1387 - loss: 0.8298 - val_accuracy: 0.1335 - val_loss: 0.7903\n",
      "Epoch 43/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1402 - loss: 0.8288 - val_accuracy: 0.1340 - val_loss: 0.7883\n",
      "Epoch 44/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1401 - loss: 0.8254 - val_accuracy: 0.1347 - val_loss: 0.7869\n",
      "Epoch 45/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1404 - loss: 0.8244 - val_accuracy: 0.1348 - val_loss: 0.7851\n",
      "Epoch 46/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1411 - loss: 0.8211 - val_accuracy: 0.1348 - val_loss: 0.7832\n",
      "Epoch 47/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1415 - loss: 0.8220 - val_accuracy: 0.1360 - val_loss: 0.7820\n",
      "Epoch 48/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1421 - loss: 0.8223 - val_accuracy: 0.1357 - val_loss: 0.7802\n",
      "Epoch 49/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1415 - loss: 0.8199 - val_accuracy: 0.1350 - val_loss: 0.7817\n",
      "Epoch 50/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1414 - loss: 0.8184 - val_accuracy: 0.1344 - val_loss: 0.7852\n",
      "Restoring model weights from the end of the best epoch: 48.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▂▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.14193</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.81768</td></tr><tr><td>epoch/val_accuracy</td><td>0.13438</td></tr><tr><td>epoch/val_loss</td><td>0.78517</td></tr><tr><td>val_exact_match_accuracy</td><td>0.13438</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-4</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/h6vwylba' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/h6vwylba</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_141058-h6vwylba\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nj2tm2g2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_141800-nj2tm2g2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/nj2tm2g2' target=\"_blank\">light-sweep-5</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/nj2tm2g2' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/nj2tm2g2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run nj2tm2g2 with config: {'batch_size': 356, 'beam_size': 5, 'cell_type': 'GRU', 'decoder_layers': 2, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 1, 'epochs': 50, 'hidden_size': 256, 'input_embedding_size': 64, 'learning_rate': 0.001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run nj2tm2g2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 250ms/step - accuracy: 0.0567 - loss: 1.2560 - val_accuracy: 0.0715 - val_loss: 1.0170\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 240ms/step - accuracy: 0.0786 - loss: 1.0446 - val_accuracy: 0.0827 - val_loss: 0.9488\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.0944 - loss: 0.9608 - val_accuracy: 0.0979 - val_loss: 0.8666\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 225ms/step - accuracy: 0.1100 - loss: 0.8840 - val_accuracy: 0.1193 - val_loss: 0.7936\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.1273 - loss: 0.8153 - val_accuracy: 0.1322 - val_loss: 0.7353\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.1434 - loss: 0.7490 - val_accuracy: 0.1536 - val_loss: 0.6595\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 258ms/step - accuracy: 0.1652 - loss: 0.6685 - val_accuracy: 0.1787 - val_loss: 0.5679\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 259ms/step - accuracy: 0.1894 - loss: 0.5740 - val_accuracy: 0.2000 - val_loss: 0.4823\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 258ms/step - accuracy: 0.2096 - loss: 0.4894 - val_accuracy: 0.2162 - val_loss: 0.4110\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 254ms/step - accuracy: 0.2280 - loss: 0.4228 - val_accuracy: 0.2308 - val_loss: 0.3581\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 257ms/step - accuracy: 0.2432 - loss: 0.3658 - val_accuracy: 0.2439 - val_loss: 0.3139\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 258ms/step - accuracy: 0.2544 - loss: 0.3252 - val_accuracy: 0.2515 - val_loss: 0.2816\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 259ms/step - accuracy: 0.2632 - loss: 0.2914 - val_accuracy: 0.2562 - val_loss: 0.2614\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 268ms/step - accuracy: 0.2704 - loss: 0.2679 - val_accuracy: 0.2599 - val_loss: 0.2452\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 261ms/step - accuracy: 0.2754 - loss: 0.2473 - val_accuracy: 0.2634 - val_loss: 0.2329\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 278ms/step - accuracy: 0.2801 - loss: 0.2305 - val_accuracy: 0.2670 - val_loss: 0.2210\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 260ms/step - accuracy: 0.2832 - loss: 0.2185 - val_accuracy: 0.2686 - val_loss: 0.2119\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.2858 - loss: 0.2060 - val_accuracy: 0.2696 - val_loss: 0.2075\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 265ms/step - accuracy: 0.2895 - loss: 0.1958 - val_accuracy: 0.2713 - val_loss: 0.2025\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 267ms/step - accuracy: 0.2911 - loss: 0.1880 - val_accuracy: 0.2715 - val_loss: 0.1998\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 278ms/step - accuracy: 0.2932 - loss: 0.1821 - val_accuracy: 0.2728 - val_loss: 0.1949\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.2957 - loss: 0.1739 - val_accuracy: 0.2732 - val_loss: 0.1929\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 257ms/step - accuracy: 0.2974 - loss: 0.1683 - val_accuracy: 0.2742 - val_loss: 0.1902\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.2987 - loss: 0.1627 - val_accuracy: 0.2740 - val_loss: 0.1880\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.3007 - loss: 0.1556 - val_accuracy: 0.2747 - val_loss: 0.1855\n",
      "Epoch 26/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.3022 - loss: 0.1507 - val_accuracy: 0.2753 - val_loss: 0.1841\n",
      "Epoch 27/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 264ms/step - accuracy: 0.3040 - loss: 0.1473 - val_accuracy: 0.2757 - val_loss: 0.1820\n",
      "Epoch 28/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 254ms/step - accuracy: 0.3058 - loss: 0.1429 - val_accuracy: 0.2760 - val_loss: 0.1817\n",
      "Epoch 29/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 270ms/step - accuracy: 0.3055 - loss: 0.1374 - val_accuracy: 0.2770 - val_loss: 0.1799\n",
      "Epoch 30/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 271ms/step - accuracy: 0.3073 - loss: 0.1346 - val_accuracy: 0.2762 - val_loss: 0.1795\n",
      "Epoch 31/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 261ms/step - accuracy: 0.3079 - loss: 0.1315 - val_accuracy: 0.2770 - val_loss: 0.1771\n",
      "Epoch 32/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 281ms/step - accuracy: 0.3094 - loss: 0.1273 - val_accuracy: 0.2779 - val_loss: 0.1755\n",
      "Epoch 33/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.3105 - loss: 0.1246 - val_accuracy: 0.2777 - val_loss: 0.1757\n",
      "Epoch 34/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 271ms/step - accuracy: 0.3125 - loss: 0.1202 - val_accuracy: 0.2775 - val_loss: 0.1757\n",
      "Epoch 35/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 273ms/step - accuracy: 0.3130 - loss: 0.1168 - val_accuracy: 0.2787 - val_loss: 0.1756\n",
      "Epoch 36/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 292ms/step - accuracy: 0.3140 - loss: 0.1153 - val_accuracy: 0.2775 - val_loss: 0.1754\n",
      "Epoch 37/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 280ms/step - accuracy: 0.3145 - loss: 0.1122 - val_accuracy: 0.2789 - val_loss: 0.1753\n",
      "Epoch 38/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 282ms/step - accuracy: 0.3148 - loss: 0.1088 - val_accuracy: 0.2781 - val_loss: 0.1748\n",
      "Epoch 39/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 281ms/step - accuracy: 0.3163 - loss: 0.1065 - val_accuracy: 0.2784 - val_loss: 0.1756\n",
      "Epoch 40/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 280ms/step - accuracy: 0.3156 - loss: 0.1040 - val_accuracy: 0.2775 - val_loss: 0.1766\n",
      "Epoch 41/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 271ms/step - accuracy: 0.3179 - loss: 0.1016 - val_accuracy: 0.2775 - val_loss: 0.1767\n",
      "Epoch 42/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 287ms/step - accuracy: 0.3189 - loss: 0.0999 - val_accuracy: 0.2780 - val_loss: 0.1773\n",
      "Epoch 43/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 269ms/step - accuracy: 0.3193 - loss: 0.0972 - val_accuracy: 0.2780 - val_loss: 0.1790\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▆▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▂▃▃▄▅▅▆▆▇▇▇▇██████████████████████████</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▆▆▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.31846</td></tr><tr><td>epoch/epoch</td><td>42</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.09806</td></tr><tr><td>epoch/val_accuracy</td><td>0.27797</td></tr><tr><td>epoch/val_loss</td><td>0.17905</td></tr><tr><td>val_exact_match_accuracy</td><td>0.27797</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-sweep-5</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/nj2tm2g2' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/nj2tm2g2</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_141800-nj2tm2g2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gh0gbznu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_144210-gh0gbznu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/gh0gbznu' target=\"_blank\">peach-sweep-6</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/gh0gbznu' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/gh0gbznu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run gh0gbznu with config: {'batch_size': 356, 'beam_size': 5, 'cell_type': 'LSTM', 'decoder_layers': 2, 'dropout_rate': 0.3, 'early_stopping_patience': 5, 'encoder_layers': 1, 'epochs': 50, 'hidden_size': 256, 'input_embedding_size': 64, 'learning_rate': 0.0001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run gh0gbznu ---\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.0455 - loss: 1.3691 - val_accuracy: 0.0593 - val_loss: 1.1562\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.0619 - loss: 1.2082 - val_accuracy: 0.0642 - val_loss: 1.1487\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.0645 - loss: 1.2054 - val_accuracy: 0.0636 - val_loss: 1.1482\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 282ms/step - accuracy: 0.0663 - loss: 1.1967 - val_accuracy: 0.0667 - val_loss: 1.0923\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 274ms/step - accuracy: 0.0722 - loss: 1.1516 - val_accuracy: 0.0707 - val_loss: 1.0933\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 280ms/step - accuracy: 0.0735 - loss: 1.1357 - val_accuracy: 0.0704 - val_loss: 1.0844\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 273ms/step - accuracy: 0.0745 - loss: 1.1327 - val_accuracy: 0.0704 - val_loss: 1.0906\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 278ms/step - accuracy: 0.0759 - loss: 1.1273 - val_accuracy: 0.0729 - val_loss: 1.0820\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 283ms/step - accuracy: 0.0771 - loss: 1.1241 - val_accuracy: 0.0738 - val_loss: 1.0715\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 296ms/step - accuracy: 0.0786 - loss: 1.1163 - val_accuracy: 0.0747 - val_loss: 1.0702\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 283ms/step - accuracy: 0.0796 - loss: 1.1114 - val_accuracy: 0.0762 - val_loss: 1.0580\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.0811 - loss: 1.1060 - val_accuracy: 0.0771 - val_loss: 1.0602\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 279ms/step - accuracy: 0.0829 - loss: 1.0899 - val_accuracy: 0.0785 - val_loss: 1.0395\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 274ms/step - accuracy: 0.0848 - loss: 1.0761 - val_accuracy: 0.0799 - val_loss: 1.0238\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 275ms/step - accuracy: 0.0862 - loss: 1.0628 - val_accuracy: 0.0805 - val_loss: 1.0153\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 296ms/step - accuracy: 0.0866 - loss: 1.0553 - val_accuracy: 0.0818 - val_loss: 1.0079\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 284ms/step - accuracy: 0.0872 - loss: 1.0485 - val_accuracy: 0.0822 - val_loss: 1.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 294ms/step - accuracy: 0.0882 - loss: 1.0412 - val_accuracy: 0.0822 - val_loss: 0.9978\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 291ms/step - accuracy: 0.0883 - loss: 1.0379 - val_accuracy: 0.0822 - val_loss: 1.0005\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 271ms/step - accuracy: 0.0887 - loss: 1.0316 - val_accuracy: 0.0844 - val_loss: 0.9886\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 265ms/step - accuracy: 0.0900 - loss: 1.0289 - val_accuracy: 0.0831 - val_loss: 0.9986\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 276ms/step - accuracy: 0.0909 - loss: 1.0233 - val_accuracy: 0.0866 - val_loss: 0.9815\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.0922 - loss: 1.0172 - val_accuracy: 0.0858 - val_loss: 0.9812\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 281ms/step - accuracy: 0.0935 - loss: 1.0150 - val_accuracy: 0.0892 - val_loss: 0.9680\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 281ms/step - accuracy: 0.0946 - loss: 1.0101 - val_accuracy: 0.0875 - val_loss: 0.9766\n",
      "Epoch 26/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 276ms/step - accuracy: 0.0955 - loss: 1.0065 - val_accuracy: 0.0886 - val_loss: 0.9705\n",
      "Epoch 27/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 271ms/step - accuracy: 0.0963 - loss: 0.9984 - val_accuracy: 0.0917 - val_loss: 0.9559\n",
      "Epoch 28/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 270ms/step - accuracy: 0.0977 - loss: 0.9956 - val_accuracy: 0.0893 - val_loss: 0.9667\n",
      "Epoch 29/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 305ms/step - accuracy: 0.0982 - loss: 0.9928 - val_accuracy: 0.0901 - val_loss: 0.9641\n",
      "Epoch 30/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 268ms/step - accuracy: 0.0988 - loss: 0.9901 - val_accuracy: 0.0936 - val_loss: 0.9462\n",
      "Epoch 31/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.0992 - loss: 0.9849 - val_accuracy: 0.0943 - val_loss: 0.9436\n",
      "Epoch 32/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 283ms/step - accuracy: 0.0997 - loss: 0.9856 - val_accuracy: 0.0942 - val_loss: 0.9444\n",
      "Epoch 33/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 283ms/step - accuracy: 0.1007 - loss: 0.9792 - val_accuracy: 0.0957 - val_loss: 0.9388\n",
      "Epoch 34/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 279ms/step - accuracy: 0.1017 - loss: 0.9739 - val_accuracy: 0.0962 - val_loss: 0.9378\n",
      "Epoch 35/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 277ms/step - accuracy: 0.1032 - loss: 0.9699 - val_accuracy: 0.0969 - val_loss: 0.9351\n",
      "Epoch 36/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 275ms/step - accuracy: 0.1048 - loss: 0.9648 - val_accuracy: 0.0996 - val_loss: 0.9189\n",
      "Epoch 37/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 272ms/step - accuracy: 0.1056 - loss: 0.9552 - val_accuracy: 0.0991 - val_loss: 0.9219\n",
      "Epoch 38/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.1062 - loss: 0.9525 - val_accuracy: 0.1008 - val_loss: 0.9166\n",
      "Epoch 39/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 325ms/step - accuracy: 0.1090 - loss: 0.9461 - val_accuracy: 0.1044 - val_loss: 0.9032\n",
      "Epoch 40/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.1093 - loss: 0.9412 - val_accuracy: 0.1054 - val_loss: 0.8977\n",
      "Epoch 41/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 259ms/step - accuracy: 0.1119 - loss: 0.9323 - val_accuracy: 0.1060 - val_loss: 0.8975\n",
      "Epoch 42/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 265ms/step - accuracy: 0.1135 - loss: 0.9259 - val_accuracy: 0.1057 - val_loss: 0.8944\n",
      "Epoch 43/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 259ms/step - accuracy: 0.1157 - loss: 0.9133 - val_accuracy: 0.1079 - val_loss: 0.8873\n",
      "Epoch 44/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.1174 - loss: 0.9068 - val_accuracy: 0.1147 - val_loss: 0.8590\n",
      "Epoch 45/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.1203 - loss: 0.8998 - val_accuracy: 0.1153 - val_loss: 0.8625\n",
      "Epoch 46/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.1217 - loss: 0.8934 - val_accuracy: 0.1158 - val_loss: 0.8570\n",
      "Epoch 47/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.1227 - loss: 0.8848 - val_accuracy: 0.1189 - val_loss: 0.8482\n",
      "Epoch 48/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.1238 - loss: 0.8798 - val_accuracy: 0.1169 - val_loss: 0.8532\n",
      "Epoch 49/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 257ms/step - accuracy: 0.1255 - loss: 0.8762 - val_accuracy: 0.1150 - val_loss: 0.8559\n",
      "Epoch 50/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.1268 - loss: 0.8706 - val_accuracy: 0.1179 - val_loss: 0.8476\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆█████</td></tr><tr><td>epoch/val_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.12701</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.86836</td></tr><tr><td>epoch/val_accuracy</td><td>0.11786</td></tr><tr><td>epoch/val_loss</td><td>0.84756</td></tr><tr><td>val_exact_match_accuracy</td><td>0.11786</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-6</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/gh0gbznu' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/gh0gbznu</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_144210-gh0gbznu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yehc77n9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_151114-yehc77n9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/yehc77n9' target=\"_blank\">lyric-sweep-7</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/yehc77n9' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/yehc77n9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run yehc77n9 with config: {'batch_size': 64, 'beam_size': 5, 'cell_type': 'LSTM', 'decoder_layers': 1, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 64, 'learning_rate': 0.001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run yehc77n9 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.0656 - loss: 1.2026 - val_accuracy: 0.0881 - val_loss: 0.9758\n",
      "Epoch 2/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1007 - loss: 0.9868 - val_accuracy: 0.1109 - val_loss: 0.8784\n",
      "Epoch 3/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1250 - loss: 0.8861 - val_accuracy: 0.1358 - val_loss: 0.7891\n",
      "Epoch 4/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1452 - loss: 0.8066 - val_accuracy: 0.1477 - val_loss: 0.7376\n",
      "Epoch 5/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1554 - loss: 0.7617 - val_accuracy: 0.1545 - val_loss: 0.7018\n",
      "Epoch 6/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1627 - loss: 0.7234 - val_accuracy: 0.1610 - val_loss: 0.6707\n",
      "Epoch 7/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1692 - loss: 0.6950 - val_accuracy: 0.1642 - val_loss: 0.6543\n",
      "Epoch 8/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1736 - loss: 0.6794 - val_accuracy: 0.1716 - val_loss: 0.6305\n",
      "Epoch 9/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1788 - loss: 0.6604 - val_accuracy: 0.1752 - val_loss: 0.6193\n",
      "Epoch 10/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1830 - loss: 0.6434 - val_accuracy: 0.1795 - val_loss: 0.6016\n",
      "Epoch 11/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1865 - loss: 0.6290 - val_accuracy: 0.1808 - val_loss: 0.5920\n",
      "Epoch 12/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1903 - loss: 0.6159 - val_accuracy: 0.1827 - val_loss: 0.5865\n",
      "Epoch 13/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1921 - loss: 0.6096 - val_accuracy: 0.1877 - val_loss: 0.5704\n",
      "Epoch 14/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1954 - loss: 0.5960 - val_accuracy: 0.1893 - val_loss: 0.5623\n",
      "Epoch 15/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1974 - loss: 0.5853 - val_accuracy: 0.1911 - val_loss: 0.5530\n",
      "Epoch 16/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2002 - loss: 0.5782 - val_accuracy: 0.1934 - val_loss: 0.5459\n",
      "Epoch 17/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2022 - loss: 0.5675 - val_accuracy: 0.1957 - val_loss: 0.5364\n",
      "Epoch 18/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2042 - loss: 0.5579 - val_accuracy: 0.1963 - val_loss: 0.5317\n",
      "Epoch 19/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2065 - loss: 0.5541 - val_accuracy: 0.1991 - val_loss: 0.5236\n",
      "Epoch 20/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2076 - loss: 0.5445 - val_accuracy: 0.1986 - val_loss: 0.5223\n",
      "Epoch 21/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2100 - loss: 0.5397 - val_accuracy: 0.2007 - val_loss: 0.5115\n",
      "Epoch 22/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2114 - loss: 0.5311 - val_accuracy: 0.2003 - val_loss: 0.5132\n",
      "Epoch 23/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2136 - loss: 0.5278 - val_accuracy: 0.2044 - val_loss: 0.5023\n",
      "Epoch 24/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2147 - loss: 0.5190 - val_accuracy: 0.2046 - val_loss: 0.4992\n",
      "Epoch 25/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2157 - loss: 0.5155 - val_accuracy: 0.2051 - val_loss: 0.4950\n",
      "Epoch 26/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2167 - loss: 0.5104 - val_accuracy: 0.2075 - val_loss: 0.4905\n",
      "Epoch 27/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2175 - loss: 0.5076 - val_accuracy: 0.2059 - val_loss: 0.4923\n",
      "Epoch 28/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2190 - loss: 0.5026 - val_accuracy: 0.2077 - val_loss: 0.4838\n",
      "Epoch 29/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2200 - loss: 0.4963 - val_accuracy: 0.2075 - val_loss: 0.4837\n",
      "Epoch 30/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2201 - loss: 0.4928 - val_accuracy: 0.2078 - val_loss: 0.4788\n",
      "Epoch 31/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2214 - loss: 0.4888 - val_accuracy: 0.2103 - val_loss: 0.4727\n",
      "Epoch 32/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2226 - loss: 0.4854 - val_accuracy: 0.2096 - val_loss: 0.4715\n",
      "Epoch 33/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2237 - loss: 0.4813 - val_accuracy: 0.2110 - val_loss: 0.4645\n",
      "Epoch 34/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2247 - loss: 0.4770 - val_accuracy: 0.2114 - val_loss: 0.4635\n",
      "Epoch 35/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2257 - loss: 0.4753 - val_accuracy: 0.2126 - val_loss: 0.4630\n",
      "Epoch 36/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2268 - loss: 0.4704 - val_accuracy: 0.2105 - val_loss: 0.4664\n",
      "Epoch 37/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2269 - loss: 0.4713 - val_accuracy: 0.2131 - val_loss: 0.4557\n",
      "Epoch 38/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.2281 - loss: 0.4641 - val_accuracy: 0.2150 - val_loss: 0.4515\n",
      "Epoch 39/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.2291 - loss: 0.4606 - val_accuracy: 0.2144 - val_loss: 0.4487\n",
      "Epoch 40/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2292 - loss: 0.4574 - val_accuracy: 0.2150 - val_loss: 0.4484\n",
      "Epoch 41/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2298 - loss: 0.4549 - val_accuracy: 0.2156 - val_loss: 0.4454\n",
      "Epoch 42/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2308 - loss: 0.4515 - val_accuracy: 0.2174 - val_loss: 0.4408\n",
      "Epoch 43/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2313 - loss: 0.4538 - val_accuracy: 0.2172 - val_loss: 0.4390\n",
      "Epoch 44/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.2320 - loss: 0.4467 - val_accuracy: 0.2185 - val_loss: 0.4354\n",
      "Epoch 45/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2325 - loss: 0.4423 - val_accuracy: 0.2179 - val_loss: 0.4371\n",
      "Epoch 46/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2334 - loss: 0.4418 - val_accuracy: 0.2202 - val_loss: 0.4310\n",
      "Epoch 47/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2338 - loss: 0.4394 - val_accuracy: 0.2202 - val_loss: 0.4302\n",
      "Epoch 48/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2350 - loss: 0.4383 - val_accuracy: 0.2190 - val_loss: 0.4316\n",
      "Epoch 49/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2343 - loss: 0.4331 - val_accuracy: 0.2158 - val_loss: 0.4398\n",
      "Epoch 50/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.2348 - loss: 0.4369 - val_accuracy: 0.2200 - val_loss: 0.4270\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇██████████</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.23494</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.43397</td></tr><tr><td>epoch/val_accuracy</td><td>0.22004</td></tr><tr><td>epoch/val_loss</td><td>0.42699</td></tr><tr><td>val_exact_match_accuracy</td><td>0.22004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-7</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/yehc77n9' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/yehc77n9</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_151114-yehc77n9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: arxk04o1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_152415-arxk04o1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/arxk04o1' target=\"_blank\">crimson-sweep-8</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/arxk04o1' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/arxk04o1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run arxk04o1 with config: {'batch_size': 128, 'beam_size': 1, 'cell_type': 'GRU', 'decoder_layers': 2, 'dropout_rate': 0.3, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 128, 'learning_rate': 0.001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run arxk04o1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.0562 - loss: 1.2408 - val_accuracy: 0.0754 - val_loss: 1.0064\n",
      "Epoch 2/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.0891 - loss: 1.0139 - val_accuracy: 0.0967 - val_loss: 0.9083\n",
      "Epoch 3/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.1056 - loss: 0.9374 - val_accuracy: 0.1127 - val_loss: 0.8441\n",
      "Epoch 4/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.1185 - loss: 0.8806 - val_accuracy: 0.1218 - val_loss: 0.7971\n",
      "Epoch 5/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1265 - loss: 0.8377 - val_accuracy: 0.1321 - val_loss: 0.7495\n",
      "Epoch 6/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1355 - loss: 0.7949 - val_accuracy: 0.1426 - val_loss: 0.7064\n",
      "Epoch 7/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.1445 - loss: 0.7542 - val_accuracy: 0.1508 - val_loss: 0.6693\n",
      "Epoch 8/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1520 - loss: 0.7186 - val_accuracy: 0.1602 - val_loss: 0.6290\n",
      "Epoch 9/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1599 - loss: 0.6872 - val_accuracy: 0.1674 - val_loss: 0.5956\n",
      "Epoch 10/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.1672 - loss: 0.6542 - val_accuracy: 0.1747 - val_loss: 0.5641\n",
      "Epoch 11/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.1730 - loss: 0.6253 - val_accuracy: 0.1809 - val_loss: 0.5380\n",
      "Epoch 12/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1790 - loss: 0.6029 - val_accuracy: 0.1872 - val_loss: 0.5169\n",
      "Epoch 13/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1840 - loss: 0.5779 - val_accuracy: 0.1912 - val_loss: 0.4981\n",
      "Epoch 14/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1886 - loss: 0.5589 - val_accuracy: 0.1973 - val_loss: 0.4788\n",
      "Epoch 15/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1938 - loss: 0.5420 - val_accuracy: 0.2032 - val_loss: 0.4637\n",
      "Epoch 16/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.1997 - loss: 0.5259 - val_accuracy: 0.2083 - val_loss: 0.4458\n",
      "Epoch 17/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2040 - loss: 0.5138 - val_accuracy: 0.2124 - val_loss: 0.4325\n",
      "Epoch 18/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2072 - loss: 0.4986 - val_accuracy: 0.2159 - val_loss: 0.4185\n",
      "Epoch 19/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2113 - loss: 0.4893 - val_accuracy: 0.2204 - val_loss: 0.4057\n",
      "Epoch 20/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2152 - loss: 0.4749 - val_accuracy: 0.2239 - val_loss: 0.3944\n",
      "Epoch 21/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2185 - loss: 0.4647 - val_accuracy: 0.2251 - val_loss: 0.3855\n",
      "Epoch 22/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.2207 - loss: 0.4527 - val_accuracy: 0.2275 - val_loss: 0.3754\n",
      "Epoch 23/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2236 - loss: 0.4474 - val_accuracy: 0.2300 - val_loss: 0.3689\n",
      "Epoch 24/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2254 - loss: 0.4388 - val_accuracy: 0.2317 - val_loss: 0.3610\n",
      "Epoch 25/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2280 - loss: 0.4275 - val_accuracy: 0.2342 - val_loss: 0.3527\n",
      "Epoch 26/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2298 - loss: 0.4240 - val_accuracy: 0.2354 - val_loss: 0.3479\n",
      "Epoch 27/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.2317 - loss: 0.4188 - val_accuracy: 0.2387 - val_loss: 0.3407\n",
      "Epoch 28/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2330 - loss: 0.4129 - val_accuracy: 0.2378 - val_loss: 0.3379\n",
      "Epoch 29/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2342 - loss: 0.4043 - val_accuracy: 0.2392 - val_loss: 0.3351\n",
      "Epoch 30/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2367 - loss: 0.3996 - val_accuracy: 0.2408 - val_loss: 0.3296\n",
      "Epoch 31/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2377 - loss: 0.3939 - val_accuracy: 0.2425 - val_loss: 0.3252\n",
      "Epoch 32/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2394 - loss: 0.3892 - val_accuracy: 0.2438 - val_loss: 0.3214\n",
      "Epoch 33/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2401 - loss: 0.3849 - val_accuracy: 0.2441 - val_loss: 0.3179\n",
      "Epoch 34/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2408 - loss: 0.3838 - val_accuracy: 0.2443 - val_loss: 0.3161\n",
      "Epoch 35/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2418 - loss: 0.3786 - val_accuracy: 0.2444 - val_loss: 0.3134\n",
      "Epoch 36/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2437 - loss: 0.3758 - val_accuracy: 0.2466 - val_loss: 0.3078\n",
      "Epoch 37/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2439 - loss: 0.3729 - val_accuracy: 0.2473 - val_loss: 0.3069\n",
      "Epoch 38/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2441 - loss: 0.3693 - val_accuracy: 0.2479 - val_loss: 0.3056\n",
      "Epoch 39/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.2456 - loss: 0.3666 - val_accuracy: 0.2484 - val_loss: 0.3016\n",
      "Epoch 40/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.2460 - loss: 0.3651 - val_accuracy: 0.2483 - val_loss: 0.3008\n",
      "Epoch 41/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2468 - loss: 0.3605 - val_accuracy: 0.2466 - val_loss: 0.3046\n",
      "Epoch 42/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.2468 - loss: 0.3622 - val_accuracy: 0.2485 - val_loss: 0.2980\n",
      "Epoch 43/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2473 - loss: 0.3565 - val_accuracy: 0.2501 - val_loss: 0.2931\n",
      "Epoch 44/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.2487 - loss: 0.3574 - val_accuracy: 0.2503 - val_loss: 0.2925\n",
      "Epoch 45/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2484 - loss: 0.3523 - val_accuracy: 0.2504 - val_loss: 0.2897\n",
      "Epoch 46/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.2495 - loss: 0.3491 - val_accuracy: 0.2509 - val_loss: 0.2890\n",
      "Epoch 47/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.2500 - loss: 0.3488 - val_accuracy: 0.2513 - val_loss: 0.2876\n",
      "Epoch 48/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.2504 - loss: 0.3470 - val_accuracy: 0.2526 - val_loss: 0.2846\n",
      "Epoch 49/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.2517 - loss: 0.3461 - val_accuracy: 0.2505 - val_loss: 0.2889\n",
      "Epoch 50/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.2518 - loss: 0.3410 - val_accuracy: 0.2533 - val_loss: 0.2809\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.25198</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.34255</td></tr><tr><td>epoch/val_accuracy</td><td>0.25333</td></tr><tr><td>epoch/val_loss</td><td>0.28092</td></tr><tr><td>val_exact_match_accuracy</td><td>0.25333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-8</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/arxk04o1' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/arxk04o1</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_152415-arxk04o1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6vnocnb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_153716-a6vnocnb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/a6vnocnb' target=\"_blank\">distinctive-sweep-9</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/a6vnocnb' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/a6vnocnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run a6vnocnb with config: {'batch_size': 64, 'beam_size': 3, 'cell_type': 'LSTM', 'decoder_layers': 2, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 1, 'epochs': 50, 'hidden_size': 64, 'input_embedding_size': 32, 'learning_rate': 0.0001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run a6vnocnb ---\n",
      "Epoch 1/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.0487 - loss: 1.3222 - val_accuracy: 0.0635 - val_loss: 1.1477\n",
      "Epoch 2/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0662 - loss: 1.1947 - val_accuracy: 0.0658 - val_loss: 1.1349\n",
      "Epoch 3/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0706 - loss: 1.1816 - val_accuracy: 0.0705 - val_loss: 1.1298\n",
      "Epoch 4/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0739 - loss: 1.1768 - val_accuracy: 0.0707 - val_loss: 1.1261\n",
      "Epoch 5/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0743 - loss: 1.1700 - val_accuracy: 0.0722 - val_loss: 1.1184\n",
      "Epoch 6/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0782 - loss: 1.1669 - val_accuracy: 0.0762 - val_loss: 1.1142\n",
      "Epoch 7/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0822 - loss: 1.1548 - val_accuracy: 0.0777 - val_loss: 1.1103\n",
      "Epoch 8/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0837 - loss: 1.1486 - val_accuracy: 0.0784 - val_loss: 1.1072\n",
      "Epoch 9/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0843 - loss: 1.1427 - val_accuracy: 0.0791 - val_loss: 1.1039\n",
      "Epoch 10/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0847 - loss: 1.1397 - val_accuracy: 0.0791 - val_loss: 1.0966\n",
      "Epoch 11/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0855 - loss: 1.1380 - val_accuracy: 0.0795 - val_loss: 1.0977\n",
      "Epoch 12/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0852 - loss: 1.1347 - val_accuracy: 0.0796 - val_loss: 1.0953\n",
      "Epoch 13/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0859 - loss: 1.1300 - val_accuracy: 0.0799 - val_loss: 1.0898\n",
      "Epoch 14/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0862 - loss: 1.1291 - val_accuracy: 0.0799 - val_loss: 1.0863\n",
      "Epoch 15/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0860 - loss: 1.1259 - val_accuracy: 0.0784 - val_loss: 1.1006\n",
      "Epoch 16/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0864 - loss: 1.1241 - val_accuracy: 0.0804 - val_loss: 1.0810\n",
      "Epoch 17/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0870 - loss: 1.1197 - val_accuracy: 0.0797 - val_loss: 1.0861\n",
      "Epoch 18/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0871 - loss: 1.1191 - val_accuracy: 0.0811 - val_loss: 1.0808\n",
      "Epoch 19/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0879 - loss: 1.1153 - val_accuracy: 0.0818 - val_loss: 1.0785\n",
      "Epoch 20/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0886 - loss: 1.1155 - val_accuracy: 0.0810 - val_loss: 1.0817\n",
      "Epoch 21/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0888 - loss: 1.1127 - val_accuracy: 0.0835 - val_loss: 1.0667\n",
      "Epoch 22/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0889 - loss: 1.1082 - val_accuracy: 0.0833 - val_loss: 1.0673\n",
      "Epoch 23/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0892 - loss: 1.1006 - val_accuracy: 0.0827 - val_loss: 1.0661\n",
      "Epoch 24/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0896 - loss: 1.0969 - val_accuracy: 0.0820 - val_loss: 1.0489\n",
      "Epoch 25/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0880 - loss: 1.0806 - val_accuracy: 0.0834 - val_loss: 1.0217\n",
      "Epoch 26/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0893 - loss: 1.0570 - val_accuracy: 0.0850 - val_loss: 1.0123\n",
      "Epoch 27/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0910 - loss: 1.0490 - val_accuracy: 0.0861 - val_loss: 1.0042\n",
      "Epoch 28/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0924 - loss: 1.0419 - val_accuracy: 0.0878 - val_loss: 0.9963\n",
      "Epoch 29/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0926 - loss: 1.0323 - val_accuracy: 0.0893 - val_loss: 0.9895\n",
      "Epoch 30/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.0940 - loss: 1.0279 - val_accuracy: 0.0906 - val_loss: 0.9846\n",
      "Epoch 31/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0952 - loss: 1.0206 - val_accuracy: 0.0914 - val_loss: 0.9806\n",
      "Epoch 32/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0971 - loss: 1.0179 - val_accuracy: 0.0930 - val_loss: 0.9734\n",
      "Epoch 33/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0975 - loss: 1.0146 - val_accuracy: 0.0939 - val_loss: 0.9704\n",
      "Epoch 34/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0986 - loss: 1.0115 - val_accuracy: 0.0947 - val_loss: 0.9675\n",
      "Epoch 35/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0992 - loss: 1.0064 - val_accuracy: 0.0931 - val_loss: 0.9710\n",
      "Epoch 36/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.0996 - loss: 1.0033 - val_accuracy: 0.0950 - val_loss: 0.9647\n",
      "Epoch 37/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1001 - loss: 1.0006 - val_accuracy: 0.0951 - val_loss: 0.9619\n",
      "Epoch 38/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1011 - loss: 0.9992 - val_accuracy: 0.0962 - val_loss: 0.9574\n",
      "Epoch 39/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.1021 - loss: 0.9953 - val_accuracy: 0.0978 - val_loss: 0.9523\n",
      "Epoch 40/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1033 - loss: 0.9934 - val_accuracy: 0.0976 - val_loss: 0.9508\n",
      "Epoch 41/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1037 - loss: 0.9859 - val_accuracy: 0.0992 - val_loss: 0.9453\n",
      "Epoch 42/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1045 - loss: 0.9861 - val_accuracy: 0.1001 - val_loss: 0.9403\n",
      "Epoch 43/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1058 - loss: 0.9799 - val_accuracy: 0.1013 - val_loss: 0.9358\n",
      "Epoch 44/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1064 - loss: 0.9777 - val_accuracy: 0.1017 - val_loss: 0.9334\n",
      "Epoch 45/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1060 - loss: 0.9725 - val_accuracy: 0.1020 - val_loss: 0.9299\n",
      "Epoch 46/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.1077 - loss: 0.9712 - val_accuracy: 0.1018 - val_loss: 0.9293\n",
      "Epoch 47/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.1078 - loss: 0.9687 - val_accuracy: 0.1015 - val_loss: 0.9298\n",
      "Epoch 48/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1083 - loss: 0.9671 - val_accuracy: 0.1035 - val_loss: 0.9241\n",
      "Epoch 49/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1088 - loss: 0.9604 - val_accuracy: 0.1058 - val_loss: 0.9177\n",
      "Epoch 50/50\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.1099 - loss: 0.9587 - val_accuracy: 0.1031 - val_loss: 0.9231\n",
      "Restoring model weights from the end of the best epoch: 49.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▃▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▂▂▃▄▄▄▄▄▄▄▄▄▄▄▅▅▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇█████</td></tr><tr><td>epoch/val_loss</td><td>██▇▇▇▇▇▇▆▆▆▇▆▆▆▆▅▅▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_exact_match_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.10972</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.95876</td></tr><tr><td>epoch/val_accuracy</td><td>0.10305</td></tr><tr><td>epoch/val_loss</td><td>0.92312</td></tr><tr><td>val_exact_match_accuracy</td><td>0.10305</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-9</strong> at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/a6vnocnb' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/a6vnocnb</a><br> View project at: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250520_153716-a6vnocnb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pnio67bb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\prana\\Downloads\\DA6401 Assignment 3\\wandb\\run-20250520_155035-pnio67bb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/pnio67bb' target=\"_blank\">scarlet-sweep-10</a></strong> to <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/sweeps/a9aclnzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/pnio67bb' target=\"_blank\">https://wandb.ai/ce21b097-indian-institute-of-technology-madras/CE21B097%20-%20DA6401%20-%20Assignment%203/runs/pnio67bb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building model for run pnio67bb with config: {'batch_size': 128, 'beam_size': 5, 'cell_type': 'GRU', 'decoder_layers': 2, 'dropout_rate': 0.2, 'early_stopping_patience': 5, 'encoder_layers': 2, 'epochs': 50, 'hidden_size': 256, 'input_embedding_size': 128, 'learning_rate': 0.0001, 'optimizer': 'nadam'} ---\n",
      "--- Starting training for run pnio67bb ---\n",
      "Epoch 1/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 205ms/step - accuracy: 0.0532 - loss: 1.3037 - val_accuracy: 0.0685 - val_loss: 1.0566\n",
      "Epoch 2/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.0727 - loss: 1.0825 - val_accuracy: 0.0757 - val_loss: 0.9990\n",
      "Epoch 3/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 200ms/step - accuracy: 0.0821 - loss: 1.0337 - val_accuracy: 0.0836 - val_loss: 0.9551\n",
      "Epoch 4/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.0907 - loss: 0.9826 - val_accuracy: 0.0886 - val_loss: 0.9204\n",
      "Epoch 5/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 204ms/step - accuracy: 0.0949 - loss: 0.9505 - val_accuracy: 0.0889 - val_loss: 0.9058\n",
      "Epoch 6/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.0989 - loss: 0.9299 - val_accuracy: 0.0948 - val_loss: 0.8840\n",
      "Epoch 7/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 201ms/step - accuracy: 0.1022 - loss: 0.9117 - val_accuracy: 0.0964 - val_loss: 0.8685\n",
      "Epoch 8/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.1052 - loss: 0.9022 - val_accuracy: 0.1002 - val_loss: 0.8550\n",
      "Epoch 9/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 204ms/step - accuracy: 0.1083 - loss: 0.8851 - val_accuracy: 0.1033 - val_loss: 0.8426\n",
      "Epoch 10/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.1117 - loss: 0.8755 - val_accuracy: 0.1052 - val_loss: 0.8326\n",
      "Epoch 11/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.1142 - loss: 0.8620 - val_accuracy: 0.1084 - val_loss: 0.8209\n",
      "Epoch 12/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1162 - loss: 0.8514 - val_accuracy: 0.1108 - val_loss: 0.8110\n",
      "Epoch 13/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 205ms/step - accuracy: 0.1185 - loss: 0.8411 - val_accuracy: 0.1109 - val_loss: 0.8066\n",
      "Epoch 14/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1198 - loss: 0.8341 - val_accuracy: 0.1150 - val_loss: 0.7926\n",
      "Epoch 15/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 200ms/step - accuracy: 0.1228 - loss: 0.8250 - val_accuracy: 0.1163 - val_loss: 0.7851\n",
      "Epoch 16/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 201ms/step - accuracy: 0.1244 - loss: 0.8151 - val_accuracy: 0.1204 - val_loss: 0.7731\n",
      "Epoch 17/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.1273 - loss: 0.8058 - val_accuracy: 0.1222 - val_loss: 0.7644\n",
      "Epoch 18/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1291 - loss: 0.7985 - val_accuracy: 0.1235 - val_loss: 0.7649\n",
      "Epoch 19/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 201ms/step - accuracy: 0.1308 - loss: 0.7888 - val_accuracy: 0.1263 - val_loss: 0.7508\n",
      "Epoch 20/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1332 - loss: 0.7817 - val_accuracy: 0.1273 - val_loss: 0.7444\n",
      "Epoch 21/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 202ms/step - accuracy: 0.1353 - loss: 0.7755 - val_accuracy: 0.1308 - val_loss: 0.7351\n",
      "Epoch 22/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1367 - loss: 0.7660 - val_accuracy: 0.1319 - val_loss: 0.7284\n",
      "Epoch 23/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 203ms/step - accuracy: 0.1391 - loss: 0.7570 - val_accuracy: 0.1333 - val_loss: 0.7224\n",
      "Epoch 24/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 204ms/step - accuracy: 0.1407 - loss: 0.7527 - val_accuracy: 0.1346 - val_loss: 0.7161\n",
      "Epoch 25/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 208ms/step - accuracy: 0.1421 - loss: 0.7433 - val_accuracy: 0.1376 - val_loss: 0.7071\n",
      "Epoch 26/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 216ms/step - accuracy: 0.1443 - loss: 0.7336 - val_accuracy: 0.1389 - val_loss: 0.6992\n",
      "Epoch 27/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 217ms/step - accuracy: 0.1466 - loss: 0.7287 - val_accuracy: 0.1402 - val_loss: 0.6922\n",
      "Epoch 28/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 215ms/step - accuracy: 0.1478 - loss: 0.7194 - val_accuracy: 0.1423 - val_loss: 0.6840\n",
      "Epoch 29/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 215ms/step - accuracy: 0.1500 - loss: 0.7131 - val_accuracy: 0.1427 - val_loss: 0.6791\n",
      "Epoch 30/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 216ms/step - accuracy: 0.1522 - loss: 0.7054 - val_accuracy: 0.1472 - val_loss: 0.6685\n",
      "Epoch 31/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 218ms/step - accuracy: 0.1542 - loss: 0.6955 - val_accuracy: 0.1489 - val_loss: 0.6629\n",
      "Epoch 32/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 230ms/step - accuracy: 0.1566 - loss: 0.6898 - val_accuracy: 0.1517 - val_loss: 0.6541\n",
      "Epoch 33/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 229ms/step - accuracy: 0.1580 - loss: 0.6802 - val_accuracy: 0.1538 - val_loss: 0.6460\n",
      "Epoch 34/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 230ms/step - accuracy: 0.1604 - loss: 0.6718 - val_accuracy: 0.1560 - val_loss: 0.6389\n",
      "Epoch 35/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 229ms/step - accuracy: 0.1629 - loss: 0.6668 - val_accuracy: 0.1580 - val_loss: 0.6318\n",
      "Epoch 36/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 233ms/step - accuracy: 0.1652 - loss: 0.6606 - val_accuracy: 0.1594 - val_loss: 0.6244\n",
      "Epoch 37/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 229ms/step - accuracy: 0.1674 - loss: 0.6528 - val_accuracy: 0.1626 - val_loss: 0.6159\n",
      "Epoch 38/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 230ms/step - accuracy: 0.1692 - loss: 0.6421 - val_accuracy: 0.1639 - val_loss: 0.6087\n",
      "Epoch 39/50\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 226ms/step - accuracy: 0.1706 - loss: 0.6350 - val_accuracy: 0.1670 - val_loss: 0.6034\n",
      "Epoch 40/50\n",
      "\u001b[1m133/346\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 216ms/step - accuracy: 0.1725 - loss: 0.6273"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 9: Start the Sweep Agent\n",
    "\n",
    "# --- Initialize Sweep ---\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"ce21b097-indian-institute-of-technology-madras\", project=\"CE21B097 - DA6401 - Assignment 3\")\n",
    "\n",
    "# --- Run Agent ---\n",
    "# The 'count' parameter specifies how many runs the agent should perform.\n",
    "# For a thorough search, this might be 20-50 or more, depending on your compute budget.\n",
    "# For testing, set count to a small number like 3-5.\n",
    "wandb.agent(sweep_id, function=train_evaluate, count=30) # Example: 10 runs\n",
    "\n",
    "print(\"\\n--- Sweep Finished ---\")\n",
    "print(\"Go to your W&B project page to see the results, including:\")\n",
    "print(\"- Accuracy v/s Created plot\")\n",
    "print(\"- Parallel Co-ordinates plot\")\n",
    "print(\"- Correlation Summary table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0b051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
